batch_size,vocab_size,config_name,use_flash,seq_len,n_layers,h_dim,mlp_dim,head_dim,n_heads,compile,class,config,performance test,number of parameters,number of non-embedding parameters,device,model memory usage megabytes,step memory usage in megabytes,tokens per batch,avg step duration in ms,std step duration in ms,avg iterations per second,std iterations per second,tokens per second,OOM,flops,macs,params
1,16384,tiny,False,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 1, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpggeg36qk/throughput_results_bsz1.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz1_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,53912064,41329152,NVIDIA GeForce RTX 3090,462.158203125,663.73388671875,512,20.279867308480398,1.410274422879202,49.30998732826184,3.1267588082756683,25247,False,45.13 G,20.94 GMACs,53.91 M
8,16384,tiny,False,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 8, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpggeg36qk/throughput_results_bsz8.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz8_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,53912064,41329152,NVIDIA GeForce RTX 3090,462.158203125,664.26123046875,4096,37.74909537179129,0.25434408206972564,26.490701039349105,0.17736379931992444,108506,False,361.02 G,167.5 GMACs,53.91 M
16,16384,tiny,False,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 16, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpggeg36qk/throughput_results_bsz16.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz16_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,53912064,41329152,NVIDIA GeForce RTX 3090,462.158203125,676.66748046875,8192,67.69247763497489,0.9421441327889978,14.772690185642233,0.20876665918450052,121018,False,722.04 G,335.01 GMACs,53.91 M
24,16384,tiny,False,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 24, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpggeg36qk/throughput_results_bsz24.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz24_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,53912064,41329152,NVIDIA GeForce RTX 3090,462.158203125,661.07373046875,12288,94.4840589250837,0.9669769320001671,10.583795947979953,0.10752137459408771,130054,False,1083.06 G,502.51 GMACs,53.91 M
32,16384,tiny,False,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 32, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpggeg36qk/throughput_results_bsz32.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz32_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,53912064,41329152,NVIDIA GeForce RTX 3090,462.158203125,658.10498046875,16384,122.54281888689313,1.276661367198857,8.160412899616736,0.08476751626384192,133700,False,1444.04 G,670.01 GMACs,53.91 M
40,16384,tiny,False,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 40, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpggeg36qk/throughput_results_bsz40.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz40_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,53912064,41329152,NVIDIA GeForce RTX 3090,462.158203125,666.63623046875,20480,149.7619683401925,1.2311750838014435,6.677262666102553,0.05479116827831338,136750,False,1805.13 G,837.52 GMACs,53.91 M
48,16384,tiny,False,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 48, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpggeg36qk/throughput_results_bsz48.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz48_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,53912064,41329152,NVIDIA GeForce RTX 3090,462.158203125,658.91748046875,24576,180.4558552333287,1.8969765708560349,5.541521491264465,0.05850569480394768,136188,False
56,16384,tiny,False,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 56, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpggeg36qk/throughput_results_bsz56.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz56_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,53912064,41329152,NVIDIA GeForce RTX 3090,462.158203125,659.32373046875,28672,207.94473920549666,1.3754370512141956,4.808969939902028,0.03171639063420439,137883,False
64,16384,tiny,False,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 64, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpggeg36qk/throughput_results_bsz64.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz64_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,53912064,41329152,NVIDIA GeForce RTX 3090,462.158203125,661.72998046875,32768,235.57669285365515,1.7247860258833092,4.2449021076173254,0.03098006414970249,139097,False
72,16384,tiny,False,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 72, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpggeg36qk/throughput_results_bsz72.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz72_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,53912064,41329152,NVIDIA GeForce RTX 3090,462.158203125,661.26171875,36864,264.6778455461775,1.3502739476413073,3.778177950392653,0.019264692627881087,139279,False
76,16384,tiny,False,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 76, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpggeg36qk/throughput_results_bsz76.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz76_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,53912064,41329152,NVIDIA GeForce RTX 3090,462.158203125,663.15234375,38912,274.29055568150113,1.6736687889631436,3.6457689821488906,0.02207376449449305,141864,False
77,16384,tiny,False,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 77, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpggeg36qk/throughput_results_bsz77.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz77_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,53912064,41329152,NVIDIA GeForce RTX 3090,462.158203125,662.28125,39424,280.27408272879467,0.602005467126314,3.5679360369814974,0.0076725696385054375,140662,False
78,16384,tiny,False,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 77, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpggeg36qk/throughput_results_bsz77.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz77_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,53912064,41329152,NVIDIA GeForce RTX 3090,0,0,0,0,0,0,0,0,True
80,16384,tiny,False,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 77, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpggeg36qk/throughput_results_bsz77.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz77_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,53912064,41329152,NVIDIA GeForce RTX 3090,0,0,0,0,0,0,0,0,True
1,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 1, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpiq5rtru0/throughput_results_bsz1.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz1_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,27549696,19161088,NVIDIA GeForce RTX 3090,361.09375,347.54052734375,512,19.68808909824916,1.6393678936136846,50.79213096861334,4.4663228121553145,26006,False,20.42 G,9.66 GMACs,27.55 M
8,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 8, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpiq5rtru0/throughput_results_bsz8.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz8_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,27549696,19161088,NVIDIA GeForce RTX 3090,361.09375,347.56787109375,4096,25.985492842538015,0.5034409893240049,38.48301073447447,0.729791489286586,157626,False,163.37 G,77.31 GMACs,27.55 M
16,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 16, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpiq5rtru0/throughput_results_bsz16.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz16_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,27549696,19161088,NVIDIA GeForce RTX 3090,361.09375,347.59912109375,8192,42.632388251168386,2.0720693039358085,23.456344835961517,1.1403744614951754,192154,False,326.74 G,154.62 GMACs,27.55 M
24,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 24, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpiq5rtru0/throughput_results_bsz24.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz24_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,27549696,19161088,NVIDIA GeForce RTX 3090,361.09375,347.63037109375,12288,57.1943359375,0.27450564657923143,17.484248809056293,0.08393542368672553,214846,False,490.11 G,231.93 GMACs,27.55 M
32,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 32, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpiq5rtru0/throughput_results_bsz32.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz32_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,27549696,19161088,NVIDIA GeForce RTX 3090,361.09375,347.66162109375,16384,73.25077492850167,0.2769387903339834,13.651732708303442,0.051391592552202485,223670,False,653.48 G,309.24 GMACs,27.55 M
40,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 40, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpiq5rtru0/throughput_results_bsz40.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz40_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,27549696,19161088,NVIDIA GeForce RTX 3090,361.09375,347.69287109375,20480,87.69813646589007,1.4664083842690516,11.402750848519421,0.1847010589963349,233528,False,816.85 G,386.55 GMACs,27.55 M
48,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 48, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpiq5rtru0/throughput_results_bsz48.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz48_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,27549696,19161088,NVIDIA GeForce RTX 3090,361.09375,347.72412109375,24576,108.04565756661552,1.3433769388251189,9.255346512963284,0.11486902709479758,227459,False,980.22 G,463.86 GMACs,27.55 M
56,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 56, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpiq5rtru0/throughput_results_bsz56.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz56_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,27549696,19161088,NVIDIA GeForce RTX 3090,361.09375,347.75537109375,28672,123.29146957397461,2.2377799252993356,8.110861225480017,0.1459088435338152,232555,False,1143.59 G,541.17 GMACs,27.55 M
64,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 64, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpiq5rtru0/throughput_results_bsz64.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz64_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,27549696,19161088,NVIDIA GeForce RTX 3090,361.09375,347.78662109375,32768,138.14274052211218,1.9893935216285399,7.238889254842403,0.10337219016753314,237204,False,1306.96 G,618.48 GMACs,27.55 M
72,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 72, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpiq5rtru0/throughput_results_bsz72.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz72_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,27549696,19161088,NVIDIA GeForce RTX 3090,361.09375,347.818359375,36864,158.82340676443917,1.446413316043307,6.296301158450542,0.05689228102644887,232107,False
80,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 80, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpiq5rtru0/throughput_results_bsz80.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz80_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,27549696,19161088,NVIDIA GeForce RTX 3090,361.09375,347.849609375,40960,175.7117429460798,2.040257848940795,5.691139267264951,0.06591699806780983,233109,False
88,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 88, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpiq5rtru0/throughput_results_bsz88.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz88_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,27549696,19161088,NVIDIA GeForce RTX 3090,361.09375,347.880859375,45056,191.26217433384485,1.024294938753204,5.22842534590513,0.028303540561397524,235572,False
96,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 96, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpiq5rtru0/throughput_results_bsz96.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz96_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,27549696,19161088,NVIDIA GeForce RTX 3090,361.09375,347.912109375,49152,207.14168657575334,2.0288225254765684,4.827613487806049,0.04742805006972824,237287,False
97,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 97, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpiq5rtru0/throughput_results_bsz97.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz97_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,27549696,19161088,NVIDIA GeForce RTX 3090,361.09375,349.791015625,49664,208.04351806640625,1.8142925700315105,4.806686645631545,0.0418302145888697,238719,False
98,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 97, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpiq5rtru0/throughput_results_bsz97.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz97_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,27549696,19161088,NVIDIA GeForce RTX 3090,0,0,0,0,0,0,0,0,True
100,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 97, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpiq5rtru0/throughput_results_bsz97.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz97_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,27549696,19161088,NVIDIA GeForce RTX 3090,0,0,0,0,0,0,0,0,True
104,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 97, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpiq5rtru0/throughput_results_bsz97.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz97_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,27549696,19161088,NVIDIA GeForce RTX 3090,0,0,0,0,0,0,0,0,True
1,16384,small,False,512,12,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 1, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 12, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpvf9d021p/throughput_results_bsz1.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz1_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,110615040,98032128,NVIDIA GeForce RTX 3090,1190.462890625,1318.15576171875,512,51.256164005824495,0.2726918638608607,19.509848608381326,0.10332154258413465,9989,False,109.61 G,49.93 GMACs,110.62 M
8,16384,small,False,512,12,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 8, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 12, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpvf9d021p/throughput_results_bsz8.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz8_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,110615040,98032128,NVIDIA GeForce RTX 3090,1190.462890625,1324.18310546875,4096,92.12485613141742,0.31037180784544915,10.85483377660298,0.036441364121465,44461,False,876.86 G,399.43 GMACs,110.62 M
16,16384,small,False,512,12,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 16, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 12, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpvf9d021p/throughput_results_bsz16.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz16_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,110615040,98032128,NVIDIA GeForce RTX 3090,1190.462890625,1360.21435546875,8192,163.62713841029577,0.9100895206447419,6.111455652866676,0.033573710858278615,50065,False
24,16384,small,False,512,12,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 24, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 12, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpvf9d021p/throughput_results_bsz24.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz24_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,110615040,98032128,NVIDIA GeForce RTX 3090,1190.462890625,1308.74560546875,12288,234.08304704938615,0.4428420116509898,4.2719881367104,0.008059176646269381,52494,False
32,16384,small,False,512,12,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 32, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 12, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpvf9d021p/throughput_results_bsz32.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz32_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,110615040,98032128,NVIDIA GeForce RTX 3090,1190.462890625,1307.40185546875,16384,302.2990417480469,0.3857294406474826,3.307982698911287,0.0042191542385860556,54198,False
34,16384,small,False,512,12,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 34, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 12, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpvf9d021p/throughput_results_bsz34.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz34_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,110615040,98032128,NVIDIA GeForce RTX 3090,1190.462890625,1316.65966796875,17408,314.13142830984935,0.5012670209294643,3.1833809351085733,0.00507676774070755,55416,False
35,16384,small,False,512,12,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 34, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 12, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpvf9d021p/throughput_results_bsz34.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz34_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,110615040,98032128,NVIDIA GeForce RTX 3090,0,0,0,0,0,0,0,0,True
36,16384,small,False,512,12,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 34, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 12, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpvf9d021p/throughput_results_bsz34.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz34_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,110615040,98032128,NVIDIA GeForce RTX 3090,0,0,0,0,0,0,0,0,True
40,16384,small,False,512,12,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 34, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 12, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpvf9d021p/throughput_results_bsz34.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz34_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,110615040,98032128,NVIDIA GeForce RTX 3090,0,0,0,0,0,0,0,0,True
1,16384,medium,False,512,24,1024,4096,64,16,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 1, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 24, 'h_dim': 1024, 'mlp_dim': 4096, 'head_dim': 64, 'n_heads': 16, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpsujt2grk/throughput_results_bsz1.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz1_sl512_coslr0.0006to6e-06_h1024_ff4096_nH16_dH64_nl24_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,336390144,319612928,NVIDIA GeForce RTX 3090,2819.2265625,3897.95849609375,512,115.68453979492188,3.066291559723002,8.644197416290334,0.21299974062719199,4426,False,352.42 G,163.21 GMACs,336.39 M
8,16384,medium,False,512,24,1024,4096,64,16,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 8, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 24, 'h_dim': 1024, 'mlp_dim': 4096, 'head_dim': 64, 'n_heads': 16, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpsujt2grk/throughput_results_bsz8.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz8_sl512_coslr0.0006to6e-06_h1024_ff4096_nH16_dH64_nl24_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,336390144,319612928,NVIDIA GeForce RTX 3090,2819.2265625,3897.98583984375,4096,263.638427734375,0.5921527342525262,3.79307375102212,0.00852814094245223,15536,False
10,16384,medium,False,512,24,1024,4096,64,16,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 10, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 24, 'h_dim': 1024, 'mlp_dim': 4096, 'head_dim': 64, 'n_heads': 16, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpsujt2grk/throughput_results_bsz10.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz10_sl512_coslr0.0006to6e-06_h1024_ff4096_nH16_dH64_nl24_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,336390144,319612928,NVIDIA GeForce RTX 3090,2819.2265625,3897.99365234375,5120,308.1049150739397,0.6866661661444269,3.2456476708916435,0.007217337768398455,16618,False
11,16384,medium,False,512,24,1024,4096,64,16,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 11, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 24, 'h_dim': 1024, 'mlp_dim': 4096, 'head_dim': 64, 'n_heads': 16, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpsujt2grk/throughput_results_bsz11.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz11_sl512_coslr0.0006to6e-06_h1024_ff4096_nH16_dH64_nl24_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,336390144,319612928,NVIDIA GeForce RTX 3090,2819.2265625,3902.99755859375,5632,341.1242479596819,0.3931182244317315,2.9314831941181496,0.003378145678683462,16510,False
12,16384,medium,False,512,24,1024,4096,64,16,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 11, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 24, 'h_dim': 1024, 'mlp_dim': 4096, 'head_dim': 64, 'n_heads': 16, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpsujt2grk/throughput_results_bsz11.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz11_sl512_coslr0.0006to6e-06_h1024_ff4096_nH16_dH64_nl24_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,336390144,319612928,NVIDIA GeForce RTX 3090,0,0,0,0,0,0,0,0,True
16,16384,medium,False,512,24,1024,4096,64,16,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 11, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 24, 'h_dim': 1024, 'mlp_dim': 4096, 'head_dim': 64, 'n_heads': 16, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpsujt2grk/throughput_results_bsz11.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz11_sl512_coslr0.0006to6e-06_h1024_ff4096_nH16_dH64_nl24_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,336390144,319612928,NVIDIA GeForce RTX 3090,0,0,0,0,0,0,0,0,True
5,16384,large,False,512,24,1536,6144,96,16,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 4, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 24, 'h_dim': 1536, 'mlp_dim': 6144, 'head_dim': 96, 'n_heads': 16, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmp3p7e_lch/throughput_results_bsz4.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz4_sl512_coslr0.0006to6e-06_h1536_ff6144_nH16_dH96_nl24_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,731077632,705911808,NVIDIA GeForce RTX 3090,0,0,0,0,0,0,0,0,True
8,16384,large,False,512,24,1536,6144,96,16,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 4, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 24, 'h_dim': 1536, 'mlp_dim': 6144, 'head_dim': 96, 'n_heads': 16, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmp3p7e_lch/throughput_results_bsz4.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz4_sl512_coslr0.0006to6e-06_h1536_ff6144_nH16_dH96_nl24_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,731077632,705911808,NVIDIA GeForce RTX 3090,0,0,0,0,0,0,0,0,True
1,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz1_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 512,
 'head_dim': 32,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 2048,
 'n_gpus': 1,
 'n_heads': 8,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmpmo99709x/throughput_results_bsz1.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 1,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,27549696,19161088,Tesla V100-SXM2-32GB-LS,361.09375,347.53662109375,512,28.094756535121373,0.8085559939136854,35.59383042703701,0.9557713974523,18224,False,20.42 G,9.66 GMACs,27.55 M
8,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz8_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 512,
 'head_dim': 32,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 2048,
 'n_gpus': 1,
 'n_heads': 8,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmpmo99709x/throughput_results_bsz8.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 8,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,27549696,19161088,Tesla V100-SXM2-32GB-LS,361.09375,347.56396484375,4096,37.756927490234375,1.1749349988531583,26.485205933630183,0.8128058726738779,108483,False,163.37 G,77.31 GMACs,27.55 M
16,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz16_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 512,
 'head_dim': 32,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 2048,
 'n_gpus': 1,
 'n_heads': 8,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmpmo99709x/throughput_results_bsz16.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 16,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,27549696,19161088,Tesla V100-SXM2-32GB-LS,361.09375,347.59521484375,8192,49.26520265851702,0.2379751092056424,20.29830277836316,0.0968699130248567,166284,False,326.74 G,154.62 GMACs,27.55 M
24,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz24_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 512,
 'head_dim': 32,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 2048,
 'n_gpus': 1,
 'n_heads': 8,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmpmo99709x/throughput_results_bsz24.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 24,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,27549696,19161088,Tesla V100-SXM2-32GB-LS,361.09375,347.62646484375,12288,68.2386610848563,0.30617244197178406,14.654449312193826,0.06581829584146848,180074,False,490.11 G,231.93 GMACs,27.55 M
32,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz32_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 512,
 'head_dim': 32,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 2048,
 'n_gpus': 1,
 'n_heads': 8,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmpmo99709x/throughput_results_bsz32.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 32,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,27549696,19161088,Tesla V100-SXM2-32GB-LS,361.09375,347.65771484375,16384,87.50092097691127,0.5723732214040754,11.42845113897565,0.07465381102271838,187244,False,653.48 G,309.24 GMACs,27.55 M
40,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz40_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 512,
 'head_dim': 32,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 2048,
 'n_gpus': 1,
 'n_heads': 8,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmpmo99709x/throughput_results_bsz40.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 40,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,27549696,19161088,Tesla V100-SXM2-32GB-LS,361.09375,347.68896484375,20480,107.58185195922852,1.107141974085213,9.295248053351797,0.09505598646064194,190367,False,816.85 G,386.55 GMACs,27.55 M
48,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz48_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 512,
 'head_dim': 32,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 2048,
 'n_gpus': 1,
 'n_heads': 8,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmpmo99709x/throughput_results_bsz48.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 48,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,27549696,19161088,Tesla V100-SXM2-32GB-LS,361.09375,347.72021484375,24576,128.36939348493303,1.1417776240338184,7.7900188888667765,0.06888925151415862,191448,False,980.22 G,463.86 GMACs,27.55 M
56,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz56_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 512,
 'head_dim': 32,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 2048,
 'n_gpus': 1,
 'n_heads': 8,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmpmo99709x/throughput_results_bsz56.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 56,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,27549696,19161088,Tesla V100-SXM2-32GB-LS,361.09375,347.75146484375,28672,151.08546229771204,1.0858643580870302,6.6187704944736,0.04730328117605351,189773,False,1143.59 G,541.17 GMACs,27.55 M
64,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz64_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 512,
 'head_dim': 32,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 2048,
 'n_gpus': 1,
 'n_heads': 8,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmpmo99709x/throughput_results_bsz64.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 64,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,27549696,19161088,Tesla V100-SXM2-32GB-LS,361.09375,347.78271484375,32768,170.02210889543807,1.7353845083943635,5.881588026972364,0.060270488529344836,192728,False,1306.96 G,618.48 GMACs,27.55 M
72,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz72_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 512,
 'head_dim': 32,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 2048,
 'n_gpus': 1,
 'n_heads': 8,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmpmo99709x/throughput_results_bsz72.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 72,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,27549696,19161088,Tesla V100-SXM2-32GB-LS,361.09375,347.814453125,36864,192.91927337646484,2.739588806487376,5.183515272984616,0.07356420727376733,191085,False,1470.33 G,695.78 GMACs,27.55 M
80,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz80_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 512,
 'head_dim': 32,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 2048,
 'n_gpus': 1,
 'n_heads': 8,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmpmo99709x/throughput_results_bsz80.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 80,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,27549696,19161088,Tesla V100-SXM2-32GB-LS,361.09375,347.845703125,40960,215.71609824044364,2.523493199880854,4.635722638026625,0.05432765978797103,189879,False,1633.72 G,773.09 GMACs,27.55 M
88,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz88_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 512,
 'head_dim': 32,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 2048,
 'n_gpus': 1,
 'n_heads': 8,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmpmo99709x/throughput_results_bsz88.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 88,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,27549696,19161088,Tesla V100-SXM2-32GB-LS,361.09375,347.876953125,45056,238.92597852434432,5.274384243790101,4.185396691377825,0.09017941645045048,188577,False,1797.06 G,850.4 GMACs,27.55 M
96,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz96_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 512,
 'head_dim': 32,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 2048,
 'n_gpus': 1,
 'n_heads': 8,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmpmo99709x/throughput_results_bsz96.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 96,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,27549696,19161088,Tesla V100-SXM2-32GB-LS,361.09375,347.908203125,49152,253.19142150878906,1.7059035202750337,3.9495808903829186,0.026544002267041067,194130,False
104,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz104_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 512,
 'head_dim': 32,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 2048,
 'n_gpus': 1,
 'n_heads': 8,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmpmo99709x/throughput_results_bsz104.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 104,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,27549696,19161088,Tesla V100-SXM2-32GB-LS,361.09375,347.939453125,53248,280.930899483817,2.5874945622414764,3.5595941985641386,0.03289177428969005,189541,False
112,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz112_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 512,
 'head_dim': 32,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 2048,
 'n_gpus': 1,
 'n_heads': 8,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmpmo99709x/throughput_results_bsz112.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 112,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,27549696,19161088,Tesla V100-SXM2-32GB-LS,361.09375,347.970703125,57344,303.8441946847098,3.66192648345044,3.2911604614913594,0.039457162719765376,188728,False
120,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz120_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 512,
 'head_dim': 32,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 2048,
 'n_gpus': 1,
 'n_heads': 8,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmpmo99709x/throughput_results_bsz120.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 120,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,27549696,19161088,Tesla V100-SXM2-32GB-LS,361.09375,348.001953125,61440,327.16311427525113,5.5611697123282084,3.0565792913887995,0.05206627405464464,187796,False
128,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz128_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 512,
 'head_dim': 32,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 2048,
 'n_gpus': 1,
 'n_heads': 8,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmpmo99709x/throughput_results_bsz128.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 128,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,27549696,19161088,Tesla V100-SXM2-32GB-LS,361.09375,348.033203125,65536,342.4410836356027,6.668041725825591,2.920210359642819,0.056612419432870105,191379,False
132,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz132_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 512,
 'head_dim': 32,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 2048,
 'n_gpus': 1,
 'n_heads': 8,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmpmo99709x/throughput_results_bsz132.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 132,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,27549696,19161088,Tesla V100-SXM2-32GB-LS,361.09375,349.04931640625,67584,351.048586164202,4.256436917683769,2.848608538569225,0.033975580908648384,192520,False
134,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz134_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 512,
 'head_dim': 32,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 2048,
 'n_gpus': 1,
 'n_heads': 8,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmpmo99709x/throughput_results_bsz134.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 134,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,27549696,19161088,Tesla V100-SXM2-32GB-LS,361.09375,348.05712890625,68608,357.1198163713728,5.628073212719025,2.8001806513030045,0.04373628997295315,192115,False
135,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz134_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 512,
 'head_dim': 32,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 2048,
 'n_gpus': 1,
 'n_heads': 8,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmpmo99709x/throughput_results_bsz134.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 134,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,27549696,19161088,Tesla V100-SXM2-32GB-LS,0,0,0,0,0,0,0,0,True
136,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz134_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 512,
 'head_dim': 32,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 2048,
 'n_gpus': 1,
 'n_heads': 8,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmpmo99709x/throughput_results_bsz134.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 134,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,27549696,19161088,Tesla V100-SXM2-32GB-LS,0,0,0,0,0,0,0,0,True
1,16384,tiny,False,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz1_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 768,
 'head_dim': 64,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 3072,
 'n_gpus': 1,
 'n_heads': 12,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmpv6dyzynt/throughput_results_bsz1.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 1,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,53912064,41329152,Tesla V100-SXM2-32GB-LS,462.158203125,663.72998046875,512,31.390576090131486,0.4522454932436116,31.856694733116996,0.45242077094862404,16311,False,45.13 G,20.94 GMACs,53.91 M
8,16384,tiny,False,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz8_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 768,
 'head_dim': 64,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 3072,
 'n_gpus': 1,
 'n_heads': 12,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmpv6dyzynt/throughput_results_bsz8.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 8,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,53912064,41329152,Tesla V100-SXM2-32GB-LS,462.158203125,664.88232421875,4096,48.079214096069336,0.21863036413050468,20.79900886070752,0.09506805409027723,85193,False,361.02 G,167.5 GMACs,53.91 M
16,16384,tiny,False,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz16_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 768,
 'head_dim': 64,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 3072,
 'n_gpus': 1,
 'n_heads': 12,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmpv6dyzynt/throughput_results_bsz16.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 16,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,53912064,41329152,Tesla V100-SXM2-32GB-LS,462.158203125,673.41357421875,8192,83.20975603376117,0.5305759828370147,12.017821559220343,0.07690387500235828,98450,False,722.04 G,335.01 GMACs,53.91 M
24,16384,tiny,False,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz24_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 768,
 'head_dim': 64,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 3072,
 'n_gpus': 1,
 'n_heads': 12,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmpv6dyzynt/throughput_results_bsz24.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 24,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,53912064,41329152,Tesla V100-SXM2-32GB-LS,462.158203125,661.06982421875,12288,120.51222392490932,1.0458429288941877,8.29791341850181,0.07190417318747822,101965,False,1083.06 G,502.51 GMACs,53.91 M
32,16384,tiny,False,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz32_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 768,
 'head_dim': 64,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 3072,
 'n_gpus': 1,
 'n_heads': 12,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmpv6dyzynt/throughput_results_bsz32.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 32,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,53912064,41329152,Tesla V100-SXM2-32GB-LS,462.158203125,658.10107421875,16384,155.01499829973494,1.210348481952384,6.450988684762059,0.050657453560480625,105693,False,1444.04 G,670.01 GMACs,53.91 M
40,16384,tiny,False,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz40_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 768,
 'head_dim': 64,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 3072,
 'n_gpus': 1,
 'n_heads': 12,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmpv6dyzynt/throughput_results_bsz40.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 40,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,53912064,41329152,Tesla V100-SXM2-32GB-LS,462.158203125,666.63232421875,20480,190.59635162353516,1.789672891834417,5.246690146384304,0.04881164759254048,107452,False,1805.13 G,837.52 GMACs,53.91 M
48,16384,tiny,False,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz48_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 768,
 'head_dim': 64,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 3072,
 'n_gpus': 1,
 'n_heads': 12,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmpv6dyzynt/throughput_results_bsz48.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 48,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,53912064,41329152,Tesla V100-SXM2-32GB-LS,462.158203125,658.91357421875,24576,229.71004486083984,3.4595130186082415,4.353314199236729,0.06440600425119004,106987,False,2166.14 G,1005.02 GMACs,53.91 M
56,16384,tiny,False,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz56_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 768,
 'head_dim': 64,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 3072,
 'n_gpus': 1,
 'n_heads': 12,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmpv6dyzynt/throughput_results_bsz56.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 56,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,53912064,41329152,Tesla V100-SXM2-32GB-LS,462.158203125,660.06982421875,28672,265.9790780203683,2.1906676474368414,3.75969421145005,0.031067737632300734,107798,False,2527.15 G,1172.53 GMACs,53.91 M
64,16384,tiny,False,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz64_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 768,
 'head_dim': 64,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 3072,
 'n_gpus': 1,
 'n_heads': 12,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmpv6dyzynt/throughput_results_bsz64.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 64,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,53912064,41329152,Tesla V100-SXM2-32GB-LS,462.158203125,661.72607421875,32768,302.92879159109935,2.2505039398522837,3.301105830012435,0.02458004717130342,108171,False
72,16384,tiny,False,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz72_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 768,
 'head_dim': 64,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 3072,
 'n_gpus': 1,
 'n_heads': 12,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmpv6dyzynt/throughput_results_bsz72.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 72,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,53912064,41329152,Tesla V100-SXM2-32GB-LS,462.158203125,659.3828125,36864,341.875730242048,2.740051152425313,2.925039455980101,0.023486112370133667,107829,False
80,16384,tiny,False,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz80_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 768,
 'head_dim': 64,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 3072,
 'n_gpus': 1,
 'n_heads': 12,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmpv6dyzynt/throughput_results_bsz80.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 80,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,53912064,41329152,Tesla V100-SXM2-32GB-LS,462.158203125,661.7890625,40960,379.5027749197824,5.927027397709519,2.635026845881102,0.041124841671743476,107931,False
88,16384,tiny,False,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz88_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 768,
 'head_dim': 64,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 3072,
 'n_gpus': 1,
 'n_heads': 12,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmpv6dyzynt/throughput_results_bsz88.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 88,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,53912064,41329152,Tesla V100-SXM2-32GB-LS,462.158203125,660.9453125,45056,419.7365243094308,5.585457212452265,2.382446944890594,0.031877378437481375,107344,False
96,16384,tiny,False,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz96_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 768,
 'head_dim': 64,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 3072,
 'n_gpus': 1,
 'n_heads': 12,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmpv6dyzynt/throughput_results_bsz96.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 96,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,53912064,41329152,Tesla V100-SXM2-32GB-LS,462.158203125,659.9765625,49152,455.05315072195873,5.337132698454967,2.1975454920232127,0.025733109464550083,108014,False
104,16384,tiny,False,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz104_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 768,
 'head_dim': 64,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 3072,
 'n_gpus': 1,
 'n_heads': 12,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmpv6dyzynt/throughput_results_bsz104.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 104,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,53912064,41329152,Tesla V100-SXM2-32GB-LS,462.158203125,662.3828125,53248,492.0316053118025,6.521401707998895,2.0323897676579046,0.026948999837589235,108221,False
106,16384,tiny,False,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz106_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 768,
 'head_dim': 64,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 3072,
 'n_gpus': 1,
 'n_heads': 12,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmpv6dyzynt/throughput_results_bsz106.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 106,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,53912064,41329152,Tesla V100-SXM2-32GB-LS,462.158203125,661.390625,54272,506.018801007952,3.0182719329722505,1.97621115659749,0.011844618550865507,107253,False
107,16384,tiny,False,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz106_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 768,
 'head_dim': 64,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 3072,
 'n_gpus': 1,
 'n_heads': 12,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmpv6dyzynt/throughput_results_bsz106.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 106,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,53912064,41329152,Tesla V100-SXM2-32GB-LS,0,0,0,0,0,0,0,0,True
108,16384,tiny,False,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz106_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 768,
 'head_dim': 64,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 3072,
 'n_gpus': 1,
 'n_heads': 12,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmpv6dyzynt/throughput_results_bsz106.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 106,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,53912064,41329152,Tesla V100-SXM2-32GB-LS,0,0,0,0,0,0,0,0,True
112,16384,tiny,False,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz106_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 768,
 'head_dim': 64,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 3072,
 'n_gpus': 1,
 'n_heads': 12,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmpv6dyzynt/throughput_results_bsz106.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 106,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,53912064,41329152,Tesla V100-SXM2-32GB-LS,0,0,0,0,0,0,0,0,True
1,16384,small,False,512,12,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz1_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 768,
 'head_dim': 64,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 3072,
 'n_gpus': 1,
 'n_heads': 12,
 'n_layers': 12,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmpt_icwxka/throughput_results_bsz1.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 1,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,110615040,98032128,Tesla V100-SXM2-32GB-LS,1190.462890625,1318.64404296875,512,83.8323222569057,0.4464188523783247,11.928573288659255,0.06327405392145428,6107,False,109.61 G,49.93 GMACs,110.62 M
8,16384,small,False,512,12,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz8_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 768,
 'head_dim': 64,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 3072,
 'n_gpus': 1,
 'n_heads': 12,
 'n_layers': 12,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmpt_icwxka/throughput_results_bsz8.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 8,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,110615040,98032128,Tesla V100-SXM2-32GB-LS,1190.462890625,1324.42138671875,4096,122.66217803955078,0.8021077327837173,8.152472228868815,0.05326761395675017,33393,False,876.86 G,399.43 GMACs,110.62 M
16,16384,small,False,512,12,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz16_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 768,
 'head_dim': 64,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 3072,
 'n_gpus': 1,
 'n_heads': 12,
 'n_layers': 12,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmpt_icwxka/throughput_results_bsz16.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 16,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,110615040,98032128,Tesla V100-SXM2-32GB-LS,1190.462890625,1360.20263671875,8192,206.50279453822546,1.0464270793691879,4.842549478500599,0.02451346303288441,39670,False,1753.73 G,798.86 GMACs,110.62 M
24,16384,small,False,512,12,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz24_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 768,
 'head_dim': 64,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 3072,
 'n_gpus': 1,
 'n_heads': 12,
 'n_layers': 12,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmpt_icwxka/throughput_results_bsz24.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 24,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,110615040,98032128,Tesla V100-SXM2-32GB-LS,1190.462890625,1308.73388671875,12288,295.60618373325894,1.4248044458698481,3.382879165012166,0.016337122681972613,41569,False
32,16384,small,False,512,12,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz32_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 768,
 'head_dim': 64,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 3072,
 'n_gpus': 1,
 'n_heads': 12,
 'n_layers': 12,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmpt_icwxka/throughput_results_bsz32.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 32,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,110615040,98032128,Tesla V100-SXM2-32GB-LS,1190.462890625,1307.39013671875,16384,385.01439121791293,1.7588369737398397,2.5973055106763883,0.01187795098084253,42554,False
40,16384,small,False,512,12,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz40_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 768,
 'head_dim': 64,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 3072,
 'n_gpus': 1,
 'n_heads': 12,
 'n_layers': 12,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmpt_icwxka/throughput_results_bsz40.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 40,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,110615040,98032128,Tesla V100-SXM2-32GB-LS,1190.462890625,1332.67138671875,20480,473.1468985421317,2.993748067275534,2.1135085172939254,0.013283358316733553,43285,False
48,16384,small,False,512,12,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz48_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 768,
 'head_dim': 64,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 3072,
 'n_gpus': 1,
 'n_heads': 12,
 'n_layers': 12,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmpt_icwxka/throughput_results_bsz48.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 48,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,110615040,98032128,Tesla V100-SXM2-32GB-LS,1190.462890625,1308.07763671875,24576,565.2208033970425,2.818929099309144,1.7692200888394132,0.008762096204382203,43480,False
50,16384,small,False,512,12,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz50_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 768,
 'head_dim': 64,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 3072,
 'n_gpus': 1,
 'n_heads': 12,
 'n_layers': 12,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmpt_icwxka/throughput_results_bsz50.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 50,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,110615040,98032128,Tesla V100-SXM2-32GB-LS,1190.462890625,1309.46044921875,25600,583.9515293666294,2.4962008478927245,1.7124708982004528,0.007344916296814865,43839,False
51,16384,small,False,512,12,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz50_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 768,
 'head_dim': 64,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 3072,
 'n_gpus': 1,
 'n_heads': 12,
 'n_layers': 12,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmpt_icwxka/throughput_results_bsz50.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 50,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,110615040,98032128,Tesla V100-SXM2-32GB-LS,0,0,0,0,0,0,0,0,True
52,16384,small,False,512,12,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz50_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 768,
 'head_dim': 64,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 3072,
 'n_gpus': 1,
 'n_heads': 12,
 'n_layers': 12,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmpt_icwxka/throughput_results_bsz50.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 50,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,110615040,98032128,Tesla V100-SXM2-32GB-LS,0,0,0,0,0,0,0,0,True
56,16384,small,False,512,12,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz50_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 768,
 'head_dim': 64,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 3072,
 'n_gpus': 1,
 'n_heads': 12,
 'n_layers': 12,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmpt_icwxka/throughput_results_bsz50.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 50,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,110615040,98032128,Tesla V100-SXM2-32GB-LS,0,0,0,0,0,0,0,0,True
1,16384,medium,False,512,24,1024,4096,64,16,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz1_sl512_coslr0.0006to6e-06_h1024_ff4096_nH16_dH64_nl24_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 1024,
 'head_dim': 64,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 4096,
 'n_gpus': 1,
 'n_heads': 16,
 'n_layers': 24,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmpmghsff_t/throughput_results_bsz1.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 1,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,336390144,319612928,Tesla V100-SXM2-32GB-LS,2819.2265625,3897.93505859375,512,193.44215720040458,2.1209648274308344,5.169503972001345,0.05557867793482923,2647,False,352.42 G,163.21 GMACs,336.39 M
8,16384,medium,False,512,24,1024,4096,64,16,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz8_sl512_coslr0.0006to6e-06_h1024_ff4096_nH16_dH64_nl24_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 1024,
 'head_dim': 64,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 4096,
 'n_gpus': 1,
 'n_heads': 16,
 'n_layers': 24,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmpmghsff_t/throughput_results_bsz8.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 8,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,336390144,319612928,Tesla V100-SXM2-32GB-LS,2819.2265625,3897.96240234375,4096,325.1777103969029,1.4391839279873557,3.0752415310982655,0.013683723739047865,12596,False,2819.33 G,1305.67 GMACs,336.39 M
16,16384,medium,False,512,24,1024,4096,64,16,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz16_sl512_coslr0.0006to6e-06_h1024_ff4096_nH16_dH64_nl24_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 1024,
 'head_dim': 64,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 4096,
 'n_gpus': 1,
 'n_heads': 16,
 'n_layers': 24,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmpmghsff_t/throughput_results_bsz16.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 16,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,336390144,319612928,Tesla V100-SXM2-32GB-LS,2819.2265625,3897.99365234375,8192,580.0751386369977,2.9514968225997045,1.7239145989771247,0.00878453200950117,14122,False
17,16384,medium,False,512,24,1024,4096,64,16,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz17_sl512_coslr0.0006to6e-06_h1024_ff4096_nH16_dH64_nl24_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 1024,
 'head_dim': 64,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 4096,
 'n_gpus': 1,
 'n_heads': 16,
 'n_layers': 24,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmpmghsff_t/throughput_results_bsz17.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 17,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,336390144,319612928,Tesla V100-SXM2-32GB-LS,2819.2265625,3950.99755859375,8704,605.0082746233259,2.189347813429267,1.6528699555763817,0.0059803832297107,14387,False
18,16384,medium,False,512,24,1024,4096,64,16,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz17_sl512_coslr0.0006to6e-06_h1024_ff4096_nH16_dH64_nl24_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 1024,
 'head_dim': 64,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 4096,
 'n_gpus': 1,
 'n_heads': 16,
 'n_layers': 24,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmpmghsff_t/throughput_results_bsz17.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 17,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,336390144,319612928,Tesla V100-SXM2-32GB-LS,0,0,0,0,0,0,0,0,True
20,16384,medium,False,512,24,1024,4096,64,16,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz17_sl512_coslr0.0006to6e-06_h1024_ff4096_nH16_dH64_nl24_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 1024,
 'head_dim': 64,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 4096,
 'n_gpus': 1,
 'n_heads': 16,
 'n_layers': 24,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmpmghsff_t/throughput_results_bsz17.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 17,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,336390144,319612928,Tesla V100-SXM2-32GB-LS,0,0,0,0,0,0,0,0,True
24,16384,medium,False,512,24,1024,4096,64,16,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz17_sl512_coslr0.0006to6e-06_h1024_ff4096_nH16_dH64_nl24_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 1024,
 'head_dim': 64,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 4096,
 'n_gpus': 1,
 'n_heads': 16,
 'n_layers': 24,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmpmghsff_t/throughput_results_bsz17.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 17,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,336390144,319612928,Tesla V100-SXM2-32GB-LS,0,0,0,0,0,0,0,0,True
1,16384,large,False,512,24,1536,6144,96,16,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz1_sl512_coslr0.0006to6e-06_h1536_ff6144_nH16_dH96_nl24_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 1536,
 'head_dim': 96,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 6144,
 'n_gpus': 1,
 'n_heads': 16,
 'n_layers': 24,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmppx33io_k/throughput_results_bsz1.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 1,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,731077632,705911808,Tesla V100-SXM2-32GB-LS,4324.83984375,8431.27490234375,512,242.4795423235212,0.7037619222973194,4.124059252247266,0.011912791312153713,2112,False,760.5 G,360.78 GMACs,731.08 M
8,16384,large,False,512,24,1536,6144,96,16,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz8_sl512_coslr0.0006to6e-06_h1536_ff6144_nH16_dH96_nl24_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 1536,
 'head_dim': 96,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 6144,
 'n_gpus': 1,
 'n_heads': 16,
 'n_layers': 24,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmppx33io_k/throughput_results_bsz8.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 8,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,731077632,705911808,Tesla V100-SXM2-32GB-LS,4324.83984375,8434.67724609375,4096,587.1990530831473,3.9333985606996618,1.7030000214567786,0.01139762109057467,6975,False
9,16384,large,False,512,24,1536,6144,96,16,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz9_sl512_coslr0.0006to6e-06_h1536_ff6144_nH16_dH96_nl24_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 1536,
 'head_dim': 96,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 6144,
 'n_gpus': 1,
 'n_heads': 16,
 'n_layers': 24,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmppx33io_k/throughput_results_bsz9.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 9,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,731077632,705911808,Tesla V100-SXM2-32GB-LS,4324.83984375,8435.68115234375,4608,631.6082458496094,2.709422513356731,1.5832598870758052,0.006789419372554657,7296,False
10,16384,large,False,512,24,1536,6144,96,16,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz9_sl512_coslr0.0006to6e-06_h1536_ff6144_nH16_dH96_nl24_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 1536,
 'head_dim': 96,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 6144,
 'n_gpus': 1,
 'n_heads': 16,
 'n_layers': 24,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmppx33io_k/throughput_results_bsz9.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 9,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,731077632,705911808,Tesla V100-SXM2-32GB-LS,0,0,0,0,0,0,0,0,True
12,16384,large,False,512,24,1536,6144,96,16,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz9_sl512_coslr0.0006to6e-06_h1536_ff6144_nH16_dH96_nl24_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 1536,
 'head_dim': 96,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 6144,
 'n_gpus': 1,
 'n_heads': 16,
 'n_layers': 24,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmppx33io_k/throughput_results_bsz9.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 9,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,731077632,705911808,Tesla V100-SXM2-32GB-LS,0,0,0,0,0,0,0,0,True
16,16384,large,False,512,24,1536,6144,96,16,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"{'compile': 'default',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz9_sl512_coslr0.0006to6e-06_h1536_ff6144_nH16_dH96_nl24_clip0.0_decay500k_gpus1_defaultCompile_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 1536,
 'head_dim': 96,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 6144,
 'n_gpus': 1,
 'n_heads': 16,
 'n_layers': 24,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmppx33io_k/throughput_results_bsz9.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 9,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,731077632,705911808,Tesla V100-SXM2-32GB-LS,0,0,0,0,0,0,0,0,True
1,16384,large,False,512,24,1536,6144,96,16,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 1, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 24, 'h_dim': 1536, 'mlp_dim': 6144, 'head_dim': 96, 'n_heads': 16, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpqwbqfb6_/throughput_results_bsz1.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz1_sl512_coslr0.0006to6e-06_h1536_ff6144_nH16_dH96_nl24_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,731077632,705911808,NVIDIA GeForce RTX 3090,4324.83984375,8431.29833984375,512,170.39860098702567,1.382554142797107,5.868592783083595,0.04703123728808929,3005,False,760.5 G,360.78 GMACs,731.08 M
3,16384,large,False,512,24,1536,6144,96,16,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 3, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 24, 'h_dim': 1536, 'mlp_dim': 6144, 'head_dim': 96, 'n_heads': 16, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpqwbqfb6_/throughput_results_bsz3.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz3_sl512_coslr0.0006to6e-06_h1536_ff6144_nH16_dH96_nl24_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,731077632,705911808,NVIDIA GeForce RTX 3090,4324.83984375,8431.68115234375,1536,244.50857434953963,0.49551042110654875,4.089836123989829,0.008279888375053236,6282,False,2281.51 G,1082.33 GMACs,731.08 M
4,16384,large,False,512,24,1536,6144,96,16,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 4, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 24, 'h_dim': 1536, 'mlp_dim': 6144, 'head_dim': 96, 'n_heads': 16, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpqwbqfb6_/throughput_results_bsz4.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz4_sl512_coslr0.0006to6e-06_h1536_ff6144_nH16_dH96_nl24_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,731077632,705911808,NVIDIA GeForce RTX 3090,4324.83984375,8430.81005859375,2048,290.1550859723772,0.3289812026510743,3.4464327814512274,0.003908672444987522,7058,False
5,16384,large,False,512,24,1536,6144,96,16,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 4, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 24, 'h_dim': 1536, 'mlp_dim': 6144, 'head_dim': 96, 'n_heads': 16, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpqwbqfb6_/throughput_results_bsz4.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz4_sl512_coslr0.0006to6e-06_h1536_ff6144_nH16_dH96_nl24_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,731077632,705911808,NVIDIA GeForce RTX 3090,0,0,0,0,0,0,0,0,True
8,16384,large,False,512,24,1536,6144,96,16,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 4, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 24, 'h_dim': 1536, 'mlp_dim': 6144, 'head_dim': 96, 'n_heads': 16, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpqwbqfb6_/throughput_results_bsz4.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz4_sl512_coslr0.0006to6e-06_h1536_ff6144_nH16_dH96_nl24_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,731077632,705911808,NVIDIA GeForce RTX 3090,0,0,0,0,0,0,0,0,True
1,16384,mini,False,512,4,512,2048,32,8,None,<class 'languini.projects.gpt.model.GPT'>,"{'compile': 'None',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz1_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 512,
 'head_dim': 32,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 2048,
 'n_gpus': 1,
 'n_heads': 8,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmpg2bgs41d/throughput_results_bsz1.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 1,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,27549696,19161088,Tesla P100-SXM2-16GB,361.09375,367.56591796875,512,24.097401074000768,1.1288989387210273,41.498251074009914,1.686640492582282,21247,False,20.42 G,9.66 GMACs,27.55 M
8,16384,mini,False,512,4,512,2048,32,8,None,<class 'languini.projects.gpt.model.GPT'>,"{'compile': 'None',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz8_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 512,
 'head_dim': 32,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 2048,
 'n_gpus': 1,
 'n_heads': 8,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmpg2bgs41d/throughput_results_bsz8.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 8,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,27549696,19161088,Tesla P100-SXM2-16GB,361.09375,367.59326171875,4096,112.77899333408901,0.20977793781139137,8.866899503506529,0.016459381824145903,36319,False,163.37 G,77.31 GMACs,27.55 M
16,16384,mini,False,512,4,512,2048,32,8,None,<class 'languini.projects.gpt.model.GPT'>,"{'compile': 'None',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz16_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 512,
 'head_dim': 32,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 2048,
 'n_gpus': 1,
 'n_heads': 8,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmpg2bgs41d/throughput_results_bsz16.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 16,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,27549696,19161088,Tesla P100-SXM2-16GB,361.09375,367.62451171875,8192,213.136714390346,0.9553020668016272,4.6918242258748775,0.021025918203707736,38435,False,326.74 G,154.62 GMACs,27.55 M
24,16384,mini,False,512,4,512,2048,32,8,None,<class 'languini.projects.gpt.model.GPT'>,"{'compile': 'None',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz24_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 512,
 'head_dim': 32,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 2048,
 'n_gpus': 1,
 'n_heads': 8,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmpg2bgs41d/throughput_results_bsz24.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 24,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,27549696,19161088,Tesla P100-SXM2-16GB,361.09375,367.65576171875,12288,312.2167663574219,1.435950349645806,3.2029029435761065,0.014757394575238541,39357,False,490.11 G,231.93 GMACs,27.55 M
32,16384,mini,False,512,4,512,2048,32,8,None,<class 'languini.projects.gpt.model.GPT'>,"{'compile': 'None',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz32_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 512,
 'head_dim': 32,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 2048,
 'n_gpus': 1,
 'n_heads': 8,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmpg2bgs41d/throughput_results_bsz32.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 32,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,27549696,19161088,Tesla P100-SXM2-16GB,361.09375,367.68701171875,16384,418.338623046875,0.6363406132522472,2.390408020939414,0.0036335230784917258,39164,False,653.48 G,309.24 GMACs,27.55 M
40,16384,mini,False,512,4,512,2048,32,8,None,<class 'languini.projects.gpt.model.GPT'>,"{'compile': 'None',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz40_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 512,
 'head_dim': 32,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 2048,
 'n_gpus': 1,
 'n_heads': 8,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmpg2bgs41d/throughput_results_bsz40.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 40,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,27549696,19161088,Tesla P100-SXM2-16GB,361.09375,367.71826171875,20480,515.7525591169085,1.0494149111088587,1.9389142764744371,0.003947414649662533,39709,False,816.85 G,386.55 GMACs,27.55 M
48,16384,mini,False,512,4,512,2048,32,8,None,<class 'languini.projects.gpt.model.GPT'>,"{'compile': 'None',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz48_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 512,
 'head_dim': 32,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 2048,
 'n_gpus': 1,
 'n_heads': 8,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmpg2bgs41d/throughput_results_bsz48.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 48,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,27549696,19161088,Tesla P100-SXM2-16GB,361.09375,367.74951171875,24576,614.3936941964286,1.3541532838481751,1.6276208715128655,0.003585895001612939,40000,False
56,16384,mini,False,512,4,512,2048,32,8,None,<class 'languini.projects.gpt.model.GPT'>,"{'compile': 'None',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz56_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 512,
 'head_dim': 32,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 2048,
 'n_gpus': 1,
 'n_heads': 8,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmpg2bgs41d/throughput_results_bsz56.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 56,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,27549696,19161088,Tesla P100-SXM2-16GB,361.09375,367.78076171875,28672,711.5992606026786,1.2177697308332556,1.4052853275213701,0.00240386299560836,40292,False
57,16384,mini,False,512,4,512,2048,32,8,None,<class 'languini.projects.gpt.model.GPT'>,"{'compile': 'None',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz56_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 512,
 'head_dim': 32,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 2048,
 'n_gpus': 1,
 'n_heads': 8,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmpg2bgs41d/throughput_results_bsz56.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 56,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,27549696,19161088,Tesla P100-SXM2-16GB,0,0,0,0,0,0,0,0,True
58,16384,mini,False,512,4,512,2048,32,8,None,<class 'languini.projects.gpt.model.GPT'>,"{'compile': 'None',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz56_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 512,
 'head_dim': 32,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 2048,
 'n_gpus': 1,
 'n_heads': 8,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmpg2bgs41d/throughput_results_bsz56.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 56,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,27549696,19161088,Tesla P100-SXM2-16GB,0,0,0,0,0,0,0,0,True
60,16384,mini,False,512,4,512,2048,32,8,None,<class 'languini.projects.gpt.model.GPT'>,"{'compile': 'None',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz56_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 512,
 'head_dim': 32,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 2048,
 'n_gpus': 1,
 'n_heads': 8,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmpg2bgs41d/throughput_results_bsz56.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 56,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,27549696,19161088,Tesla P100-SXM2-16GB,0,0,0,0,0,0,0,0,True
64,16384,mini,False,512,4,512,2048,32,8,None,<class 'languini.projects.gpt.model.GPT'>,"{'compile': 'None',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz56_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 512,
 'head_dim': 32,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 2048,
 'n_gpus': 1,
 'n_heads': 8,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmpg2bgs41d/throughput_results_bsz56.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 56,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,27549696,19161088,Tesla P100-SXM2-16GB,0,0,0,0,0,0,0,0,True
1,16384,tiny,False,512,4,768,3072,64,12,None,<class 'languini.projects.gpt.model.GPT'>,"{'compile': 'None',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz1_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 768,
 'head_dim': 64,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 3072,
 'n_gpus': 1,
 'n_heads': 12,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmp4e861r8i/throughput_results_bsz1.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 1,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,53912064,41329152,Tesla P100-SXM2-16GB,462.158203125,727.15771484375,512,37.23259408133371,1.0292071553242512,26.85818768940794,0.6804189696362241,13751,False,45.13 G,20.94 GMACs,53.91 M
8,16384,tiny,False,512,4,768,3072,64,12,None,<class 'languini.projects.gpt.model.GPT'>,"{'compile': 'None',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz8_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 768,
 'head_dim': 64,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 3072,
 'n_gpus': 1,
 'n_heads': 12,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmp4e861r8i/throughput_results_bsz8.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 8,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,53912064,41329152,Tesla P100-SXM2-16GB,462.158203125,729.18505859375,4096,197.7564239501953,1.1539927515465627,5.056725743846625,0.0294769902330828,20712,False,361.02 G,167.5 GMACs,53.91 M
16,16384,tiny,False,512,4,768,3072,64,12,None,<class 'languini.projects.gpt.model.GPT'>,"{'compile': 'None',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz16_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 768,
 'head_dim': 64,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 3072,
 'n_gpus': 1,
 'n_heads': 12,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmp4e861r8i/throughput_results_bsz16.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 16,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,53912064,41329152,Tesla P100-SXM2-16GB,462.158203125,731.09130859375,8192,391.753897530692,1.0985746326741457,2.552622976575887,0.007162001644484809,20911,False,722.04 G,335.01 GMACs,53.91 M
24,16384,tiny,False,512,4,768,3072,64,12,None,<class 'languini.projects.gpt.model.GPT'>,"{'compile': 'None',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz24_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 768,
 'head_dim': 64,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 3072,
 'n_gpus': 1,
 'n_heads': 12,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmp4e861r8i/throughput_results_bsz24.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 24,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,53912064,41329152,Tesla P100-SXM2-16GB,462.158203125,716.87255859375,12288,585.1948503766741,1.500477795932325,1.7088325356183962,0.00438605721819049,20998,False,1083.06 G,502.51 GMACs,53.91 M
32,16384,tiny,False,512,4,768,3072,64,12,None,<class 'languini.projects.gpt.model.GPT'>,"{'compile': 'None',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz32_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 768,
 'head_dim': 64,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 3072,
 'n_gpus': 1,
 'n_heads': 12,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmp4e861r8i/throughput_results_bsz32.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 32,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,53912064,41329152,Tesla P100-SXM2-16GB,462.158203125,715.90380859375,16384,763.91748046875,1.224140452930128,1.3090419129908988,0.002098386713721623,21447,False
40,16384,tiny,False,512,4,768,3072,64,12,None,<class 'languini.projects.gpt.model.GPT'>,"{'compile': 'None',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz40_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 768,
 'head_dim': 64,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 3072,
 'n_gpus': 1,
 'n_heads': 12,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmp4e861r8i/throughput_results_bsz40.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 40,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,53912064,41329152,Tesla P100-SXM2-16GB,462.158203125,724.31005859375,20480,954.6765790666852,2.180501599967222,1.04747515747964,0.0023882264558932544,21452,False
44,16384,tiny,False,512,4,768,3072,64,12,None,<class 'languini.projects.gpt.model.GPT'>,"{'compile': 'None',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz44_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 768,
 'head_dim': 64,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 3072,
 'n_gpus': 1,
 'n_heads': 12,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmp4e861r8i/throughput_results_bsz44.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 44,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,53912064,41329152,Tesla P100-SXM2-16GB,462.158203125,717.20068359375,22528,1050.514936174665,0.7489012330325739,0.9519141190332717,0.0006788178956236434,21445,False
45,16384,tiny,False,512,4,768,3072,64,12,None,<class 'languini.projects.gpt.model.GPT'>,"{'compile': 'None',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz44_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 768,
 'head_dim': 64,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 3072,
 'n_gpus': 1,
 'n_heads': 12,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmp4e861r8i/throughput_results_bsz44.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 44,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,53912064,41329152,Tesla P100-SXM2-16GB,0,0,0,0,0,0,0,0,True
46,16384,tiny,False,512,4,768,3072,64,12,None,<class 'languini.projects.gpt.model.GPT'>,"{'compile': 'None',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz44_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 768,
 'head_dim': 64,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 3072,
 'n_gpus': 1,
 'n_heads': 12,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmp4e861r8i/throughput_results_bsz44.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 44,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,53912064,41329152,Tesla P100-SXM2-16GB,0,0,0,0,0,0,0,0,True
48,16384,tiny,False,512,4,768,3072,64,12,None,<class 'languini.projects.gpt.model.GPT'>,"{'compile': 'None',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz44_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 768,
 'head_dim': 64,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 3072,
 'n_gpus': 1,
 'n_heads': 12,
 'n_layers': 4,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmp4e861r8i/throughput_results_bsz44.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 44,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,53912064,41329152,Tesla P100-SXM2-16GB,0,0,0,0,0,0,0,0,True
1,16384,small,False,512,12,768,3072,64,12,None,<class 'languini.projects.gpt.model.GPT'>,"{'compile': 'None',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz1_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_gpus1_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 768,
 'head_dim': 64,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 3072,
 'n_gpus': 1,
 'n_heads': 12,
 'n_layers': 12,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmps1ztv1ex/throughput_results_bsz1.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 1,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,110615040,98032128,Tesla P100-SXM2-16GB,1190.462890625,1504.42724609375,512,90.16635404314313,0.7984608175695997,11.090611466018869,0.09566005991093449,5678,False,109.61 G,49.93 GMACs,110.62 M
8,16384,small,False,512,12,768,3072,64,12,None,<class 'languini.projects.gpt.model.GPT'>,"{'compile': 'None',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz8_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_gpus1_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 768,
 'head_dim': 64,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 3072,
 'n_gpus': 1,
 'n_heads': 12,
 'n_layers': 12,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmps1ztv1ex/throughput_results_bsz8.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 8,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,110615040,98032128,Tesla P100-SXM2-16GB,1190.462890625,1512.70458984375,4096,499.34549604143416,1.5891549450468245,2.002621447329572,0.006405011432531384,8203,False,876.86 G,399.43 GMACs,110.62 M
16,16384,small,False,512,12,768,3072,64,12,None,<class 'languini.projects.gpt.model.GPT'>,"{'compile': 'None',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz16_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_gpus1_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 768,
 'head_dim': 64,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 3072,
 'n_gpus': 1,
 'n_heads': 12,
 'n_layers': 12,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmps1ztv1ex/throughput_results_bsz16.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 16,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,110615040,98032128,Tesla P100-SXM2-16GB,1190.462890625,1525.61083984375,8192,985.7547389439175,1.28165688176718,1.0144511210479639,0.0013184952511840634,8310,False
17,16384,small,False,512,12,768,3072,64,12,None,<class 'languini.projects.gpt.model.GPT'>,"{'compile': 'None',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz17_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_gpus1_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 768,
 'head_dim': 64,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 3072,
 'n_gpus': 1,
 'n_heads': 12,
 'n_layers': 12,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmps1ztv1ex/throughput_results_bsz17.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 17,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,110615040,98032128,Tesla P100-SXM2-16GB,1190.462890625,1489.98974609375,8704,1047.6559099469866,1.8118219036040435,0.954511868358192,0.0016489465560862498,8308,False
18,16384,small,False,512,12,768,3072,64,12,None,<class 'languini.projects.gpt.model.GPT'>,"{'compile': 'None',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz17_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_gpus1_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 768,
 'head_dim': 64,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 3072,
 'n_gpus': 1,
 'n_heads': 12,
 'n_layers': 12,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmps1ztv1ex/throughput_results_bsz17.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 17,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,110615040,98032128,Tesla P100-SXM2-16GB,0,0,0,0,0,0,0,0,True
20,16384,small,False,512,12,768,3072,64,12,None,<class 'languini.projects.gpt.model.GPT'>,"{'compile': 'None',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz17_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_gpus1_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 768,
 'head_dim': 64,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 3072,
 'n_gpus': 1,
 'n_heads': 12,
 'n_layers': 12,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmps1ztv1ex/throughput_results_bsz17.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 17,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,110615040,98032128,Tesla P100-SXM2-16GB,0,0,0,0,0,0,0,0,True
24,16384,small,False,512,12,768,3072,64,12,None,<class 'languini.projects.gpt.model.GPT'>,"{'compile': 'None',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz17_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_gpus1_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 768,
 'head_dim': 64,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 3072,
 'n_gpus': 1,
 'n_heads': 12,
 'n_layers': 12,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmps1ztv1ex/throughput_results_bsz17.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 17,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,110615040,98032128,Tesla P100-SXM2-16GB,0,0,0,0,0,0,0,0,True
1,16384,medium,False,512,24,1024,4096,64,16,None,<class 'languini.projects.gpt.model.GPT'>,"{'compile': 'None',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz1_sl512_coslr0.0006to6e-06_h1024_ff4096_nH16_dH64_nl24_clip0.0_decay500k_gpus1_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 1024,
 'head_dim': 64,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 4096,
 'n_gpus': 1,
 'n_heads': 16,
 'n_layers': 24,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmptuz2qywo/throughput_results_bsz1.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 1,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,336390144,319612928,Tesla P100-SXM2-16GB,2819.2265625,4474.35693359375,512,267.98594665527344,0.1456987616418194,3.731538957475112,0.002029328011319232,1911,False,352.42 G,163.21 GMACs,336.39 M
3,16384,medium,False,512,24,1024,4096,64,16,None,<class 'languini.projects.gpt.model.GPT'>,"{'compile': 'None',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz3_sl512_coslr0.0006to6e-06_h1024_ff4096_nH16_dH64_nl24_clip0.0_decay500k_gpus1_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 1024,
 'head_dim': 64,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 4096,
 'n_gpus': 1,
 'n_heads': 16,
 'n_layers': 24,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmptuz2qywo/throughput_results_bsz3.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 3,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,336390144,319612928,Tesla P100-SXM2-16GB,2819.2265625,4492.36474609375,1536,613.7327880859375,1.3252576615954454,1.629373596152037,0.0035079924340000795,2503,False,1057.27 G,489.63 GMACs,336.39 M
4,16384,medium,False,512,24,1024,4096,64,16,None,<class 'languini.projects.gpt.model.GPT'>,"{'compile': 'None',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz4_sl512_coslr0.0006to6e-06_h1024_ff4096_nH16_dH64_nl24_clip0.0_decay500k_gpus1_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 1024,
 'head_dim': 64,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 4096,
 'n_gpus': 1,
 'n_heads': 16,
 'n_layers': 24,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmptuz2qywo/throughput_results_bsz4.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 4,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,336390144,319612928,Tesla P100-SXM2-16GB,2819.2265625,4474.36865234375,2048,825.6215340750558,0.6904925062000709,1.2112087181935007,0.001012028155597385,2481,False
5,16384,medium,False,512,24,1024,4096,64,16,None,<class 'languini.projects.gpt.model.GPT'>,"{'compile': 'None',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz4_sl512_coslr0.0006to6e-06_h1024_ff4096_nH16_dH64_nl24_clip0.0_decay500k_gpus1_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 1024,
 'head_dim': 64,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 4096,
 'n_gpus': 1,
 'n_heads': 16,
 'n_layers': 24,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmptuz2qywo/throughput_results_bsz4.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 4,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,336390144,319612928,Tesla P100-SXM2-16GB,0,0,0,0,0,0,0,0,True
8,16384,medium,False,512,24,1024,4096,64,16,None,<class 'languini.projects.gpt.model.GPT'>,"{'compile': 'None',
 'data_root': '/data/languini_data/books',
 'dataset': 'books_16384',
 'debug': False,
 'decay_steps': 500000,
 'device': 'cuda',
 'eval_batch_size': 16,
 'eval_every': 2500,
 'exp_name': 'GPT_books16384_bsz4_sl512_coslr0.0006to6e-06_h1024_ff4096_nH16_dH64_nl24_clip0.0_decay500k_gpus1_fp16',
 'grad_clip_norm': 0.0,
 'gradient_accumulation_steps': 1,
 'h_dim': 1024,
 'head_dim': 64,
 'log_activations_every': 2500,
 'log_ckpt_every': 50000,
 'log_grads_every': 2500,
 'log_metrics_every': 100,
 'log_terminal_every': 100,
 'logger_type': 'all',
 'max_eval_steps': 500,
 'max_lr': 0.0006,
 'max_train_steps': 500000,
 'min_lr': 6e-06,
 'mlp_dim': 4096,
 'n_gpus': 1,
 'n_heads': 16,
 'n_layers': 24,
 'project_path': '/home/imanol/Languini/languini/projects/gpt',
 'results_pickle_file': '/tmp/tmptuz2qywo/throughput_results_bsz4.pkl',
 'seed': 0,
 'seq_len': 512,
 'test_batch_size': 16,
 'test_every': -1,
 'tokens_per_second': 0,
 'train_batch_size': 4,
 'use_flash': False,
 'vocab_size': 16384,
 'wandb_project_name': 'gpt'}",forward and backward,336390144,319612928,Tesla P100-SXM2-16GB,0,0,0,0,0,0,0,0,True
1,16384,mini,False,512,4,512,2048,32,8,None,<class 'languini.projects.gpt.model.GPT'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 1, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'None', 'results_pickle_file': '/tmp/tmpo_nbqx0m/throughput_results_bsz1.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz1_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_fp16'})",forward and backward,27549696,19161088,NVIDIA GeForce GTX TITAN X,361.09375,367.56591796875,512,39.78485516139439,0.1997158062405172,25.135192674280727,0.12600644989854723,12869,False,20.42 G,9.66 GMACs,27.55 M
8,16384,mini,False,512,4,512,2048,32,8,None,<class 'languini.projects.gpt.model.GPT'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 8, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'None', 'results_pickle_file': '/tmp/tmpo_nbqx0m/throughput_results_bsz8.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz8_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_fp16'})",forward and backward,27549696,19161088,NVIDIA GeForce GTX TITAN X,361.09375,367.59326171875,4096,186.72562844412667,0.9157349291780775,5.355451248617578,0.02625869084962513,21936,False,163.37 G,77.31 GMACs,27.55 M
16,16384,mini,False,512,4,512,2048,32,8,None,<class 'languini.projects.gpt.model.GPT'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 16, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'None', 'results_pickle_file': '/tmp/tmpo_nbqx0m/throughput_results_bsz16.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz16_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_fp16'})",forward and backward,27549696,19161088,NVIDIA GeForce GTX TITAN X,361.09375,367.62451171875,8192,378.87977382114957,1.6787188939097348,2.639359683718695,0.011703699894384733,21622,False,326.74 G,154.62 GMACs,27.55 M
24,16384,mini,False,512,4,512,2048,32,8,None,<class 'languini.projects.gpt.model.GPT'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 24, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'None', 'results_pickle_file': '/tmp/tmpo_nbqx0m/throughput_results_bsz24.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz24_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_fp16'})",forward and backward,27549696,19161088,NVIDIA GeForce GTX TITAN X,361.09375,367.65576171875,12288,602.1949201311384,5.657290255559404,1.6605918890551794,0.016092029480736167,20405,False,490.11 G,231.93 GMACs,27.55 M
32,16384,mini,False,512,4,512,2048,32,8,None,<class 'languini.projects.gpt.model.GPT'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 32, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'None', 'results_pickle_file': '/tmp/tmpo_nbqx0m/throughput_results_bsz32.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz32_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_fp16'})",forward and backward,27549696,19161088,NVIDIA GeForce GTX TITAN X,361.09375,367.68701171875,16384,755.0683070591518,0.6940832530418799,1.3243834904087164,0.001217471373478022,21699,False,653.48 G,309.24 GMACs,27.55 M
40,16384,mini,False,512,4,512,2048,32,8,None,<class 'languini.projects.gpt.model.GPT'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 40, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'None', 'results_pickle_file': '/tmp/tmpo_nbqx0m/throughput_results_bsz40.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz40_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_fp16'})",forward and backward,27549696,19161088,NVIDIA GeForce GTX TITAN X,361.09375,367.71826171875,20480,994.5086103166852,0.9496658454855564,1.005521711553172,0.0009606003978615105,20593,False
42,16384,mini,False,512,4,512,2048,32,8,None,<class 'languini.projects.gpt.model.GPT'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 42, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'None', 'results_pickle_file': '/tmp/tmpo_nbqx0m/throughput_results_bsz42.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz42_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_fp16'})",forward and backward,27549696,19161088,NVIDIA GeForce GTX TITAN X,361.09375,368.72607421875,21504,1041.6523175920759,1.0344044602332596,0.9600132242893089,0.0009529667428032628,20644,False
43,16384,mini,False,512,4,512,2048,32,8,None,<class 'languini.projects.gpt.model.GPT'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 42, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'None', 'results_pickle_file': '/tmp/tmpo_nbqx0m/throughput_results_bsz42.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz42_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_fp16'})",forward and backward,27549696,19161088,NVIDIA GeForce GTX TITAN X,0,0,0,0,0,0,0,0,True
44,16384,mini,False,512,4,512,2048,32,8,None,<class 'languini.projects.gpt.model.GPT'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 42, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'None', 'results_pickle_file': '/tmp/tmpo_nbqx0m/throughput_results_bsz42.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz42_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_fp16'})",forward and backward,27549696,19161088,NVIDIA GeForce GTX TITAN X,0,0,0,0,0,0,0,0,True
48,16384,mini,False,512,4,512,2048,32,8,None,<class 'languini.projects.gpt.model.GPT'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 42, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'None', 'results_pickle_file': '/tmp/tmpo_nbqx0m/throughput_results_bsz42.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz42_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_fp16'})",forward and backward,27549696,19161088,NVIDIA GeForce GTX TITAN X,0,0,0,0,0,0,0,0,True
1,16384,tiny,False,512,4,768,3072,64,12,None,<class 'languini.projects.gpt.model.GPT'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 1, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'None', 'results_pickle_file': '/tmp/tmp877_bwq2/throughput_results_bsz1.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz1_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_fp16'})",forward and backward,53912064,41329152,NVIDIA GeForce GTX TITAN X,462.158203125,727.15771484375,512,67.27330453055245,0.1523832678497501,14.864737312641537,0.03357915093492709,7611,False,45.13 G,20.94 GMACs,53.91 M
8,16384,tiny,False,512,4,768,3072,64,12,None,<class 'languini.projects.gpt.model.GPT'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 8, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'None', 'results_pickle_file': '/tmp/tmp877_bwq2/throughput_results_bsz8.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz8_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_fp16'})",forward and backward,53912064,41329152,NVIDIA GeForce GTX TITAN X,462.158203125,727.43505859375,4096,364.3087485177176,2.0057146503469956,2.744924474278351,0.015096161868622589,11243,False,361.02 G,167.5 GMACs,53.91 M
16,16384,tiny,False,512,4,768,3072,64,12,None,<class 'languini.projects.gpt.model.GPT'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 16, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'None', 'results_pickle_file': '/tmp/tmp877_bwq2/throughput_results_bsz16.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz16_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_fp16'})",forward and backward,53912064,41329152,NVIDIA GeForce GTX TITAN X,462.158203125,732.59130859375,8192,770.9803292410714,6.649482897705925,1.2970499532515547,0.011490816821804178,10625,False,722.04 G,335.01 GMACs,53.91 M
24,16384,tiny,False,512,4,768,3072,64,12,None,<class 'languini.projects.gpt.model.GPT'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 24, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'None', 'results_pickle_file': '/tmp/tmp877_bwq2/throughput_results_bsz24.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz24_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_fp16'})",forward and backward,53912064,41329152,NVIDIA GeForce GTX TITAN X,462.158203125,716.87255859375,12288,1127.0934361049108,0.9387716611813001,0.8872378881522642,0.0007397150032751829,10902,False
32,16384,tiny,False,512,4,768,3072,64,12,None,<class 'languini.projects.gpt.model.GPT'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 32, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'None', 'results_pickle_file': '/tmp/tmp877_bwq2/throughput_results_bsz32.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz32_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_fp16'})",forward and backward,53912064,41329152,NVIDIA GeForce GTX TITAN X,462.158203125,715.90380859375,16384,1492.354945591518,0.8978226405007426,0.6700818749279747,0.0004031906620938862,10979,False
33,16384,tiny,False,512,4,768,3072,64,12,None,<class 'languini.projects.gpt.model.GPT'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 32, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'None', 'results_pickle_file': '/tmp/tmp877_bwq2/throughput_results_bsz32.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz32_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_fp16'})",forward and backward,53912064,41329152,NVIDIA GeForce GTX TITAN X,0,0,0,0,0,0,0,0,True
34,16384,tiny,False,512,4,768,3072,64,12,None,<class 'languini.projects.gpt.model.GPT'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 32, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'None', 'results_pickle_file': '/tmp/tmp877_bwq2/throughput_results_bsz32.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz32_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_fp16'})",forward and backward,53912064,41329152,NVIDIA GeForce GTX TITAN X,0,0,0,0,0,0,0,0,True
36,16384,tiny,False,512,4,768,3072,64,12,None,<class 'languini.projects.gpt.model.GPT'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 32, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'None', 'results_pickle_file': '/tmp/tmp877_bwq2/throughput_results_bsz32.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz32_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_fp16'})",forward and backward,53912064,41329152,NVIDIA GeForce GTX TITAN X,0,0,0,0,0,0,0,0,True
40,16384,tiny,False,512,4,768,3072,64,12,None,<class 'languini.projects.gpt.model.GPT'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 32, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'None', 'results_pickle_file': '/tmp/tmp877_bwq2/throughput_results_bsz32.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz32_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_fp16'})",forward and backward,53912064,41329152,NVIDIA GeForce GTX TITAN X,0,0,0,0,0,0,0,0,True
1,16384,small,False,512,12,768,3072,64,12,None,<class 'languini.projects.gpt.model.GPT'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 1, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 12, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'None', 'results_pickle_file': '/tmp/tmps7zyku7k/throughput_results_bsz1.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz1_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_gpus1_fp16'})",forward and backward,110615040,98032128,NVIDIA GeForce GTX TITAN X,1190.462890625,1504.42724609375,512,160.1154730660575,0.0770258297008995,6.245492586387566,0.0030048066162409394,3198,False,109.61 G,49.93 GMACs,110.62 M
8,16384,small,False,512,12,768,3072,64,12,None,<class 'languini.projects.gpt.model.GPT'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 8, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 12, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'None', 'results_pickle_file': '/tmp/tmps7zyku7k/throughput_results_bsz8.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz8_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_gpus1_fp16'})",forward and backward,110615040,98032128,NVIDIA GeForce GTX TITAN X,1190.462890625,1514.95458984375,4096,941.0660661969866,34.030906355662616,1.062624650829432,0.037435881013781556,4353,False
12,16384,small,False,512,12,768,3072,64,12,None,<class 'languini.projects.gpt.model.GPT'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 12, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 12, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'None', 'results_pickle_file': '/tmp/tmps7zyku7k/throughput_results_bsz12.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz12_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_gpus1_fp16'})",forward and backward,110615040,98032128,NVIDIA GeForce GTX TITAN X,1190.462890625,1493.72021484375,6144,1452.8080095563616,0.7493536272404412,0.6883221963412537,0.0003549304454383141,4229,False
13,16384,small,False,512,12,768,3072,64,12,None,<class 'languini.projects.gpt.model.GPT'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 12, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 12, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'None', 'results_pickle_file': '/tmp/tmps7zyku7k/throughput_results_bsz12.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz12_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_gpus1_fp16'})",forward and backward,110615040,98032128,NVIDIA GeForce GTX TITAN X,0,0,0,0,0,0,0,0,True
14,16384,small,False,512,12,768,3072,64,12,None,<class 'languini.projects.gpt.model.GPT'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 12, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 12, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'None', 'results_pickle_file': '/tmp/tmps7zyku7k/throughput_results_bsz12.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz12_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_gpus1_fp16'})",forward and backward,110615040,98032128,NVIDIA GeForce GTX TITAN X,0,0,0,0,0,0,0,0,True
16,16384,small,False,512,12,768,3072,64,12,None,<class 'languini.projects.gpt.model.GPT'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 12, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 12, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'None', 'results_pickle_file': '/tmp/tmps7zyku7k/throughput_results_bsz12.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz12_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_gpus1_fp16'})",forward and backward,110615040,98032128,NVIDIA GeForce GTX TITAN X,0,0,0,0,0,0,0,0,True
1,16384,medium,False,512,24,1024,4096,64,16,None,<class 'languini.projects.gpt.model.GPT'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 1, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 24, 'h_dim': 1024, 'mlp_dim': 4096, 'head_dim': 64, 'n_heads': 16, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'None', 'results_pickle_file': '/tmp/tmp4qwndsyk/throughput_results_bsz1.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz1_sl512_coslr0.0006to6e-06_h1024_ff4096_nH16_dH64_nl24_clip0.0_decay500k_gpus1_fp16'})",forward and backward,336390144,319612928,NVIDIA GeForce GTX TITAN X,2819.2265625,4474.35693359375,512,468.5023454938616,0.6603515136353355,2.134461032304698,0.003010167106955362,1093,False,352.42 G,163.21 GMACs,336.39 M
2,16384,medium,False,512,24,1024,4096,64,16,None,<class 'languini.projects.gpt.model.GPT'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 2, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 24, 'h_dim': 1024, 'mlp_dim': 4096, 'head_dim': 64, 'n_heads': 16, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'None', 'results_pickle_file': '/tmp/tmp4qwndsyk/throughput_results_bsz2.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz2_sl512_coslr0.0006to6e-06_h1024_ff4096_nH16_dH64_nl24_clip0.0_decay500k_gpus1_fp16'})",forward and backward,336390144,319612928,NVIDIA GeForce GTX TITAN X,2819.2265625,4474.36083984375,1024,858.9616219656808,35.965771164601435,1.1641963673668696,0.04838329632194977,1192,False,704.85 G,326.42 GMACs,336.39 M
3,16384,medium,False,512,24,1024,4096,64,16,None,<class 'languini.projects.gpt.model.GPT'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 2, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 24, 'h_dim': 1024, 'mlp_dim': 4096, 'head_dim': 64, 'n_heads': 16, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'None', 'results_pickle_file': '/tmp/tmp4qwndsyk/throughput_results_bsz2.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz2_sl512_coslr0.0006to6e-06_h1024_ff4096_nH16_dH64_nl24_clip0.0_decay500k_gpus1_fp16'})",forward and backward,336390144,319612928,NVIDIA GeForce GTX TITAN X,0,0,0,0,0,0,0,0,True,704.85 G,326.42 GMACs,336.39 M
5,16384,medium,False,512,24,1024,4096,64,16,None,<class 'languini.projects.gpt.model.GPT'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 2, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 24, 'h_dim': 1024, 'mlp_dim': 4096, 'head_dim': 64, 'n_heads': 16, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'None', 'results_pickle_file': '/tmp/tmp4qwndsyk/throughput_results_bsz2.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz2_sl512_coslr0.0006to6e-06_h1024_ff4096_nH16_dH64_nl24_clip0.0_decay500k_gpus1_fp16'})",forward and backward,336390144,319612928,NVIDIA GeForce GTX TITAN X,0,0,0,0,0,0,0,0,True,704.85 G,326.42 GMACs,336.39 M
8,16384,medium,False,512,24,1024,4096,64,16,None,<class 'languini.projects.gpt.model.GPT'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 2, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 2500, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 2500, 'log_activations_every': 2500, 'log_ckpt_every': 50000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 24, 'h_dim': 1024, 'mlp_dim': 4096, 'head_dim': 64, 'n_heads': 16, 'project_path': '/home/imanol/Languini/languini/projects/gpt', 'compile': 'None', 'results_pickle_file': '/tmp/tmp4qwndsyk/throughput_results_bsz2.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz2_sl512_coslr0.0006to6e-06_h1024_ff4096_nH16_dH64_nl24_clip0.0_decay500k_gpus1_fp16'})",forward and backward,336390144,319612928,NVIDIA GeForce GTX TITAN X,0,0,0,0,0,0,0,0,True,704.85 G,326.42 GMACs,336.39 M
1,16384,tiny,False,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 1, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpn3t9s6kb/throughput_results_bsz1.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz1__sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,53912064,41329152,NVIDIA A100-SXM4-80GB,462.158203125,665.47998046875,512,20.699428830827987,0.08657167768621997,48.310511762077425,0.201957766171976,24735,False,45.13 G,20.94 GMACs,53.91 M
8,16384,tiny,False,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 8, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpn3t9s6kb/throughput_results_bsz8.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz8__sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,53912064,41329152,NVIDIA A100-SXM4-80GB,462.158203125,663.25732421875,4096,23.144374711172922,0.06659644836942859,43.20704328716433,0.12391905618071353,176976,False,361.02 G,167.5 GMACs,53.91 M
16,16384,tiny,False,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 16, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpn3t9s6kb/throughput_results_bsz16.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz16__sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,53912064,41329152,NVIDIA A100-SXM4-80GB,462.158203125,677.41357421875,8192,32.03328473227365,0.09647487793664973,31.21752915312167,0.09384097691249,255734,False,722.04 G,335.01 GMACs,53.91 M
24,16384,tiny,False,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 24, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpn3t9s6kb/throughput_results_bsz24.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz24__sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,53912064,41329152,NVIDIA A100-SXM4-80GB,462.158203125,658.44482421875,12288,42.45501954214914,0.06111247768880539,23.554340824344806,0.03392154468789938,289436,False,1083.06 G,502.51 GMACs,53.91 M
32,16384,tiny,False,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 32, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpn3t9s6kb/throughput_results_bsz32.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz32__sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,53912064,41329152,NVIDIA A100-SXM4-80GB,462.158203125,657.47607421875,16384,54.0133786882673,0.08177551608354729,18.513931627410273,0.02790204256067616,303332,False,1444.04 G,670.01 GMACs,53.91 M
40,16384,tiny,False,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 40, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpn3t9s6kb/throughput_results_bsz40.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz40__sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,53912064,41329152,NVIDIA A100-SXM4-80GB,462.158203125,666.25732421875,20480,65.33561325073242,0.12272935414022618,15.30558833453346,0.028715817561025373,313458,False,1805.13 G,837.52 GMACs,53.91 M
48,16384,tiny,False,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 48, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpn3t9s6kb/throughput_results_bsz48.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz48__sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,53912064,41329152,NVIDIA A100-SXM4-80GB,462.158203125,660.28857421875,24576,76.80852999006,0.17150152415046235,13.019387301506914,0.029053496975975143,319964,False,2166.14 G,1005.02 GMACs,53.91 M
56,16384,tiny,False,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 56, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpn3t9s6kb/throughput_results_bsz56.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz56__sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,53912064,41329152,NVIDIA A100-SXM4-80GB,462.158203125,660.06982421875,28672,88.38560213361468,0.13021275921685033,11.314059935783154,0.016669740539351875,324397,False,2527.15 G,1172.53 GMACs,53.91 M
64,16384,tiny,False,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 64, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpn3t9s6kb/throughput_results_bsz64.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz64__sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,53912064,41329152,NVIDIA A100-SXM4-80GB,462.158203125,661.72607421875,32768,99.97661481584821,0.16424089775403117,10.002339065409933,0.01643983407510915,327757,False,2888.16 G,1340.03 GMACs,53.91 M
72,16384,tiny,False,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 72, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpn3t9s6kb/throughput_results_bsz72.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz72__sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,53912064,41329152,NVIDIA A100-SXM4-80GB,462.158203125,660.3828125,36864,112.6556396484375,0.14667324455445688,8.876608424759583,0.011557198010343838,327227,False,3249.17 G,1507.53 GMACs,53.91 M
80,16384,tiny,False,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 80, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpn3t9s6kb/throughput_results_bsz80.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz80__sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,53912064,41329152,NVIDIA A100-SXM4-80GB,462.158203125,661.6640625,40960,126.54014587402344,0.32963652879341737,7.902630371515031,0.0206423840282245,323692,False,3610.18 G,1675.04 GMACs,53.91 M
88,16384,tiny,False,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 88, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpn3t9s6kb/throughput_results_bsz88.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz88__sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,53912064,41329152,NVIDIA A100-SXM4-80GB,462.158203125,660.9453125,45056,136.61465781075614,0.26259872085770203,7.3198587620461515,0.014072817404526676,329804,False,3971.19 G,1842.54 GMACs,53.91 M
96,16384,tiny,False,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 96, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpn3t9s6kb/throughput_results_bsz96.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz96__sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,53912064,41329152,NVIDIA A100-SXM4-80GB,462.158203125,659.3515625,49152,148.32100132533483,0.1560476843008711,6.742133555359089,0.007097244806782098,331389,False,4332.2 G,2010.04 GMACs,53.91 M
104,16384,tiny,False,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 104, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpn3t9s6kb/throughput_results_bsz104.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz104__sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,53912064,41329152,NVIDIA A100-SXM4-80GB,462.158203125,661.2578125,53248,159.99981253487724,0.2738323373718213,6.2500073228649375,0.010685842077997868,332800,False,4693.29 G,2177.55 GMACs,53.91 M
112,16384,tiny,False,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 112, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpn3t9s6kb/throughput_results_bsz112.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz112__sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,53912064,41329152,NVIDIA A100-SXM4-80GB,462.158203125,661.5390625,57344,171.82997567313058,0.2988701183595068,5.8197063468267265,0.010131390562977235,333725,False,5054.3 G,2345.05 GMACs,53.91 M
120,16384,tiny,False,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 120, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpn3t9s6kb/throughput_results_bsz120.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz120__sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,53912064,41329152,NVIDIA A100-SXM4-80GB,462.158203125,658.8203125,61440,184.15220860072546,0.3242462494452098,5.4302905601755596,0.009552637428713468,333637,False,5415.31 G,2512.56 GMACs,53.91 M
128,16384,tiny,False,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 128, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpn3t9s6kb/throughput_results_bsz128.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz128__sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,53912064,41329152,NVIDIA A100-SXM4-80GB,462.158203125,660.1015625,65536,195.64131382533483,0.3326848853540581,5.111394829891516,0.008696603753407202,334980,False,5776.31 G,2680.06 GMACs,53.91 M
136,16384,tiny,False,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 136, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpn3t9s6kb/throughput_results_bsz136.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz136__sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,53912064,41329152,NVIDIA A100-SXM4-80GB,462.158203125,658.75830078125,69632,207.56363242013114,0.36895917595168765,4.8177996710709525,0.008563847597554805,335473,False,6137.32 G,2847.56 GMACs,53.91 M
144,16384,tiny,False,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 144, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpn3t9s6kb/throughput_results_bsz144.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz144__sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,53912064,41329152,NVIDIA A100-SXM4-80GB,462.158203125,660.91455078125,73728,219.25177110944475,0.4467590926290808,4.560966577099284,0.009291765463299012,336271,False,6498.33 G,3015.07 GMACs,53.91 M
152,16384,tiny,False,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 152, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpn3t9s6kb/throughput_results_bsz152.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz152__sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,53912064,41329152,NVIDIA A100-SXM4-80GB,462.158203125,659.32080078125,77824,232.06165640694755,0.4067432997616124,4.3091996130820585,0.007552294245152953,335359,False,6859.34 G,3182.57 GMACs,53.91 M
160,16384,tiny,False,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 160, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpn3t9s6kb/throughput_results_bsz160.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz160__sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,53912064,41329152,NVIDIA A100-SXM4-80GB,462.158203125,661.47705078125,81920,243.58128138950892,0.36124703125352214,4.105405777880394,0.00608255544197913,336315,False
168,16384,tiny,False,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 168, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpn3t9s6kb/throughput_results_bsz168.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz168__sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,53912064,41329152,NVIDIA A100-SXM4-80GB,462.158203125,660.38330078125,86016,254.85779135567802,0.395502165226699,3.923756831920457,0.006096540681488456,337506,False
176,16384,tiny,False,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 176, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpn3t9s6kb/throughput_results_bsz176.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz176__sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,53912064,41329152,NVIDIA A100-SXM4-80GB,462.158203125,659.28955078125,90112,265.3414328438895,0.443476059532708,3.768729177656692,0.00629867149406558,339608,False
184,16384,tiny,False,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 184, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpn3t9s6kb/throughput_results_bsz184.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz184__sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,53912064,41329152,NVIDIA A100-SXM4-80GB,462.158203125,659.82080078125,94208,276.77555411202565,0.36101957620301345,3.6130358521303774,0.004712986274923107,340377,False
192,16384,tiny,False,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 192, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpn3t9s6kb/throughput_results_bsz192.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz192__sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,53912064,41329152,NVIDIA A100-SXM4-80GB,462.158203125,659.10205078125,98304,288.725588117327,0.2639238812008837,3.4634962786659504,0.0031637687605161518,340476,False
200,16384,tiny,False,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 200, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpn3t9s6kb/throughput_results_bsz200.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz200__sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,53912064,41329152,NVIDIA A100-SXM4-80GB,462.158203125,660.6337890625,102400,301.5720890590123,0.5629275929537497,3.315956735652409,0.006161412696115152,339554,False
208,16384,tiny,False,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 208, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpn3t9s6kb/throughput_results_bsz208.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz208__sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,53912064,41329152,NVIDIA A100-SXM4-80GB,462.158203125,659.7900390625,106496,312.24364798409596,0.3075581335741217,3.2026271998043487,0.0031583580400350213,341067,False
216,16384,tiny,False,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 216, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpn3t9s6kb/throughput_results_bsz216.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz216__sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,53912064,41329152,NVIDIA A100-SXM4-80GB,462.158203125,658.6962890625,110592,323.23233904157365,0.4048540299706373,3.0937498486851016,0.003874654470013597,342144,False
224,16384,tiny,False,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 224, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpn3t9s6kb/throughput_results_bsz224.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz224__sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,53912064,41329152,NVIDIA A100-SXM4-80GB,462.158203125,659.9775390625,114688,335.2319553920201,0.5087086859383546,2.983009178914941,0.004524249040433673,342115,False
232,16384,tiny,False,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 232, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpn3t9s6kb/throughput_results_bsz232.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz232__sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,53912064,41329152,NVIDIA A100-SXM4-80GB,462.158203125,660.6337890625,118784,347.5421578543527,0.5314228960486529,2.877348768776069,0.004399591957355402,341783,False
240,16384,tiny,False,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 240, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpn3t9s6kb/throughput_results_bsz240.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz240__sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,53912064,41329152,NVIDIA A100-SXM4-80GB,462.158203125,658.7900390625,122880,359.3445608956473,0.405249722112605,2.7828444028971884,0.003137920781128754,341956,False
248,16384,tiny,False,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 248, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpn3t9s6kb/throughput_results_bsz248.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz248__sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,53912064,41329152,NVIDIA A100-SXM4-80GB,462.158203125,660.0712890625,126976,370.6033695765904,0.4280634668497081,2.698302503677954,0.0031168127755503506,342620,False
256,16384,tiny,False,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 256, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpn3t9s6kb/throughput_results_bsz256.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz256__sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,53912064,41329152,NVIDIA A100-SXM4-80GB,462.158203125,661.1005859375,131072,382.19897896902904,0.44599444785961007,2.6164381775625665,0.003054450148645743,342942,False
264,16384,tiny,False,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 264, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpn3t9s6kb/throughput_results_bsz264.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz264__sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,53912064,41329152,NVIDIA A100-SXM4-80GB,462.158203125,660.2255859375,135168,394.58995928083147,0.28008699177404794,2.5342763455577324,0.001798496408043379,342553,False
272,16384,tiny,False,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 272, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpn3t9s6kb/throughput_results_bsz272.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz272__sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,53912064,41329152,NVIDIA A100-SXM4-80GB,462.158203125,661.1005859375,139264,405.80167279924666,0.5886367467134341,2.464257954142806,0.0035717163129942117,343182,False
273,16384,tiny,False,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 272, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpn3t9s6kb/throughput_results_bsz272.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz272__sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,53912064,41329152,NVIDIA A100-SXM4-80GB,0,0,0,0,0,0,0,0,True
274,16384,tiny,False,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 272, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpn3t9s6kb/throughput_results_bsz272.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz272__sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,53912064,41329152,NVIDIA A100-SXM4-80GB,0,0,0,0,0,0,0,0,True
276,16384,tiny,False,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 272, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpn3t9s6kb/throughput_results_bsz272.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz272__sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,53912064,41329152,NVIDIA A100-SXM4-80GB,0,0,0,0,0,0,0,0,True
280,16384,tiny,False,512,4,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 272, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpn3t9s6kb/throughput_results_bsz272.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz272__sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,53912064,41329152,NVIDIA A100-SXM4-80GB,0,0,0,0,0,0,0,0,True
1,16384,XL,False,512,24,2048,8192,128,24,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 1, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 24, 'h_dim': 2048, 'mlp_dim': 8192, 'head_dim': 128, 'n_heads': 24, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmp57_dc2ps/throughput_results_bsz1.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz1__sl512_coslr0.0006to6e-06_h2048_ff8192_nH24_dH128_nl24_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,1478160384,1444605952,NVIDIA A100-SXM4-80GB,7174.734375,16996.45849609375,512,189.10295758928572,0.12235004603799082,5.288124589631794,0.0034235296968511326,2708,False,1555.2 G,738.73 GMACs,1478.16 M
8,16384,XL,False,512,24,2048,8192,128,24,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 8, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 24, 'h_dim': 2048, 'mlp_dim': 8192, 'head_dim': 128, 'n_heads': 24, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmp57_dc2ps/throughput_results_bsz8.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz8__sl512_coslr0.0006to6e-06_h2048_ff8192_nH24_dH128_nl24_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,1478160384,1444605952,NVIDIA A100-SXM4-80GB,7174.734375,16996.48583984375,4096,352.0794350760324,0.2733949600099549,2.840268133763756,0.002204094271459533,11634,False,12441.25 G,5909.87 GMACs,1478.16 M
16,16384,XL,False,512,24,2048,8192,128,24,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 16, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 24, 'h_dim': 2048, 'mlp_dim': 8192, 'head_dim': 128, 'n_heads': 24, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmp57_dc2ps/throughput_results_bsz16.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz16__sl512_coslr0.0006to6e-06_h2048_ff8192_nH24_dH128_nl24_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,1478160384,1444605952,NVIDIA A100-SXM4-80GB,7174.734375,16996.51708984375,8192,588.5782557896206,0.4909287768010813,1.699009418311635,0.0014169785149538228,13918,False
20,16384,XL,False,512,24,2048,8192,128,24,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 20, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 24, 'h_dim': 2048, 'mlp_dim': 8192, 'head_dim': 128, 'n_heads': 24, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmp57_dc2ps/throughput_results_bsz20.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz20__sl512_coslr0.0006to6e-06_h2048_ff8192_nH24_dH128_nl24_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,1478160384,1444605952,NVIDIA A100-SXM4-80GB,7174.734375,16996.53271484375,10240,703.36037336077,0.4454083373065468,1.421746288068288,0.0008998901770123997,14559,False
21,16384,XL,False,512,24,2048,8192,128,24,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 20, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 24, 'h_dim': 2048, 'mlp_dim': 8192, 'head_dim': 128, 'n_heads': 24, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmp57_dc2ps/throughput_results_bsz20.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz20__sl512_coslr0.0006to6e-06_h2048_ff8192_nH24_dH128_nl24_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,1478160384,1444605952,NVIDIA A100-SXM4-80GB,0,0,0,0,0,0,0,0,True
22,16384,XL,False,512,24,2048,8192,128,24,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 20, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 24, 'h_dim': 2048, 'mlp_dim': 8192, 'head_dim': 128, 'n_heads': 24, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmp57_dc2ps/throughput_results_bsz20.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz20__sl512_coslr0.0006to6e-06_h2048_ff8192_nH24_dH128_nl24_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,1478160384,1444605952,NVIDIA A100-SXM4-80GB,0,0,0,0,0,0,0,0,True
24,16384,XL,False,512,24,2048,8192,128,24,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 20, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 24, 'h_dim': 2048, 'mlp_dim': 8192, 'head_dim': 128, 'n_heads': 24, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmp57_dc2ps/throughput_results_bsz20.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz20__sl512_coslr0.0006to6e-06_h2048_ff8192_nH24_dH128_nl24_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,1478160384,1444605952,NVIDIA A100-SXM4-80GB,0,0,0,0,0,0,0,0,True
1,16384,large,False,512,24,1536,6144,96,16,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 1, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 24, 'h_dim': 1536, 'mlp_dim': 6144, 'head_dim': 96, 'n_heads': 16, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpj7k6qvxi/throughput_results_bsz1.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz1__sl512_coslr0.0006to6e-06_h1536_ff6144_nH16_dH96_nl24_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,731077632,705911808,NVIDIA A100-SXM4-80GB,4324.83984375,8431.77490234375,512,144.76485334123885,0.17570673310298665,6.907754036422128,0.008392809958436241,3537,False,760.5 G,360.78 GMACs,731.08 M
8,16384,large,False,512,24,1536,6144,96,16,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 8, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 24, 'h_dim': 1536, 'mlp_dim': 6144, 'head_dim': 96, 'n_heads': 16, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpj7k6qvxi/throughput_results_bsz8.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz8__sl512_coslr0.0006to6e-06_h1536_ff6144_nH16_dH96_nl24_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,731077632,705911808,NVIDIA A100-SXM4-80GB,4324.83984375,8441.80224609375,4096,207.57672228131975,0.4169508024525382,4.817495858927492,0.009665078471976018,19732,False,6084.0 G,2886.22 GMACs,731.08 M
16,16384,large,False,512,24,1536,6144,96,16,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 16, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 24, 'h_dim': 1536, 'mlp_dim': 6144, 'head_dim': 96, 'n_heads': 16, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpj7k6qvxi/throughput_results_bsz16.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz16__sl512_coslr0.0006to6e-06_h1536_ff6144_nH16_dH96_nl24_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,731077632,705911808,NVIDIA A100-SXM4-80GB,4324.83984375,8430.83349609375,8192,335.70709228515625,0.3987327434808183,2.9787872314314416,0.0035350512923131784,24402,False
24,16384,large,False,512,24,1536,6144,96,16,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 24, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 24, 'h_dim': 1536, 'mlp_dim': 6144, 'head_dim': 96, 'n_heads': 16, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpj7k6qvxi/throughput_results_bsz24.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz24__sl512_coslr0.0006to6e-06_h1536_ff6144_nH16_dH96_nl24_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,731077632,705911808,NVIDIA A100-SXM4-80GB,4324.83984375,8431.73974609375,12288,469.5715659005301,0.2355474340613312,2.1296008374830584,0.0010678760705314443,26169,False
32,16384,large,False,512,24,1536,6144,96,16,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 32, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 24, 'h_dim': 1536, 'mlp_dim': 6144, 'head_dim': 96, 'n_heads': 16, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpj7k6qvxi/throughput_results_bsz32.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz32__sl512_coslr0.0006to6e-06_h1536_ff6144_nH16_dH96_nl24_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,731077632,705911808,NVIDIA A100-SXM4-80GB,4324.83984375,8430.89599609375,16384,602.899409702846,0.5978511731363234,1.6586514829942773,0.0016465001598090607,27175,False
36,16384,large,False,512,24,1536,6144,96,16,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 36, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 24, 'h_dim': 1536, 'mlp_dim': 6144, 'head_dim': 96, 'n_heads': 16, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpj7k6qvxi/throughput_results_bsz36.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz36__sl512_coslr0.0006to6e-06_h1536_ff6144_nH16_dH96_nl24_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,731077632,705911808,NVIDIA A100-SXM4-80GB,4324.83984375,8430.91162109375,18432,665.0996224539621,0.6755533531759579,1.5035341567484044,0.0015259253241966197,27713,False
38,16384,large,False,512,24,1536,6144,96,16,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 38, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 24, 'h_dim': 1536, 'mlp_dim': 6144, 'head_dim': 96, 'n_heads': 16, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpj7k6qvxi/throughput_results_bsz38.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz38__sl512_coslr0.0006to6e-06_h1536_ff6144_nH16_dH96_nl24_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,731077632,705911808,NVIDIA A100-SXM4-80GB,4324.83984375,8470.91943359375,19456,702.1966378348214,0.6942762312909531,1.4241025178978872,0.0014084205897324097,27707,False
39,16384,large,False,512,24,1536,6144,96,16,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 38, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 24, 'h_dim': 1536, 'mlp_dim': 6144, 'head_dim': 96, 'n_heads': 16, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpj7k6qvxi/throughput_results_bsz38.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz38__sl512_coslr0.0006to6e-06_h1536_ff6144_nH16_dH96_nl24_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,731077632,705911808,NVIDIA A100-SXM4-80GB,0,0,0,0,0,0,0,0,True
40,16384,large,False,512,24,1536,6144,96,16,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 38, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 24, 'h_dim': 1536, 'mlp_dim': 6144, 'head_dim': 96, 'n_heads': 16, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpj7k6qvxi/throughput_results_bsz38.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz38__sl512_coslr0.0006to6e-06_h1536_ff6144_nH16_dH96_nl24_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,731077632,705911808,NVIDIA A100-SXM4-80GB,0,0,0,0,0,0,0,0,True
1,16384,medium,False,512,24,1024,4096,64,16,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 1, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 24, 'h_dim': 1024, 'mlp_dim': 4096, 'head_dim': 64, 'n_heads': 16, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpbkn117hl/throughput_results_bsz1.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz1__sl512_coslr0.0006to6e-06_h1024_ff4096_nH16_dH64_nl24_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,336390144,319612928,NVIDIA A100-SXM4-80GB,2819.2265625,3897.93505859375,512,124.76518412998745,0.4575870955839443,8.015056499721455,0.029274228120495727,4104,False,352.42 G,163.21 GMACs,336.39 M
8,16384,medium,False,512,24,1024,4096,64,16,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 8, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 24, 'h_dim': 1024, 'mlp_dim': 4096, 'head_dim': 64, 'n_heads': 16, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpbkn117hl/throughput_results_bsz8.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz8__sl512_coslr0.0006to6e-06_h1024_ff4096_nH16_dH64_nl24_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,336390144,319612928,NVIDIA A100-SXM4-80GB,2819.2265625,3897.96240234375,4096,147.7018334524972,0.2662966817800768,6.770396660794416,0.012196214358226348,27732,False,2819.33 G,1305.67 GMACs,336.39 M
16,16384,medium,False,512,24,1024,4096,64,16,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 16, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 24, 'h_dim': 1024, 'mlp_dim': 4096, 'head_dim': 64, 'n_heads': 16, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpbkn117hl/throughput_results_bsz16.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz16__sl512_coslr0.0006to6e-06_h1024_ff4096_nH16_dH64_nl24_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,336390144,319612928,NVIDIA A100-SXM4-80GB,2819.2265625,3897.99365234375,8192,202.28758784702845,0.27011816836663244,4.94345703877891,0.006575823798183141,40497,False,5638.67 G,2611.34 GMACs,336.39 M
24,16384,medium,False,512,24,1024,4096,64,16,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 24, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 24, 'h_dim': 1024, 'mlp_dim': 4096, 'head_dim': 64, 'n_heads': 16, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpbkn117hl/throughput_results_bsz24.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz24__sl512_coslr0.0006to6e-06_h1024_ff4096_nH16_dH64_nl24_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,336390144,319612928,NVIDIA A100-SXM4-80GB,2819.2265625,3898.02490234375,12288,282.89100646972656,0.29811430823154833,3.5349303340508085,0.0037228689582297883,43437,False
32,16384,medium,False,512,24,1024,4096,64,16,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 32, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 24, 'h_dim': 1024, 'mlp_dim': 4096, 'head_dim': 64, 'n_heads': 16, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpbkn117hl/throughput_results_bsz32.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz32__sl512_coslr0.0006to6e-06_h1024_ff4096_nH16_dH64_nl24_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,336390144,319612928,NVIDIA A100-SXM4-80GB,2819.2265625,3898.05615234375,16384,362.3969247000558,0.25290261119856433,2.7594053145668043,0.0019258026318507045,45210,False
40,16384,medium,False,512,24,1024,4096,64,16,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 40, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 24, 'h_dim': 1024, 'mlp_dim': 4096, 'head_dim': 64, 'n_heads': 16, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpbkn117hl/throughput_results_bsz40.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz40__sl512_coslr0.0006to6e-06_h1024_ff4096_nH16_dH64_nl24_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,336390144,319612928,NVIDIA A100-SXM4-80GB,2819.2265625,3898.08740234375,20480,439.2704315185547,0.2502237272409992,2.2765019638198893,0.0012966880097852762,46623,False
48,16384,medium,False,512,24,1024,4096,64,16,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 48, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 24, 'h_dim': 1024, 'mlp_dim': 4096, 'head_dim': 64, 'n_heads': 16, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpbkn117hl/throughput_results_bsz48.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz48__sl512_coslr0.0006to6e-06_h1024_ff4096_nH16_dH64_nl24_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,336390144,319612928,NVIDIA A100-SXM4-80GB,2819.2265625,3898.11865234375,24576,522.1779349190848,0.46809417818029664,1.915056024255328,0.0017173144601950103,47064,False
52,16384,medium,False,512,24,1024,4096,64,16,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 52, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 24, 'h_dim': 1024, 'mlp_dim': 4096, 'head_dim': 64, 'n_heads': 16, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpbkn117hl/throughput_results_bsz52.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz52__sl512_coslr0.0006to6e-06_h1024_ff4096_nH16_dH64_nl24_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,336390144,319612928,NVIDIA A100-SXM4-80GB,2819.2265625,3898.13427734375,26624,558.0756051199777,0.3260493888214306,1.7918719091564939,0.0010465008560266039,47707,False
53,16384,medium,False,512,24,1024,4096,64,16,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 53, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 24, 'h_dim': 1024, 'mlp_dim': 4096, 'head_dim': 64, 'n_heads': 16, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpbkn117hl/throughput_results_bsz53.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz53__sl512_coslr0.0006to6e-06_h1024_ff4096_nH16_dH64_nl24_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,336390144,319612928,NVIDIA A100-SXM4-80GB,2819.2265625,3909.01318359375,27136,567.096945626395,0.4230197838739705,1.7633669299619235,0.0013154357375872372,47851,False
54,16384,medium,False,512,24,1024,4096,64,16,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 53, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 24, 'h_dim': 1024, 'mlp_dim': 4096, 'head_dim': 64, 'n_heads': 16, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpbkn117hl/throughput_results_bsz53.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz53__sl512_coslr0.0006to6e-06_h1024_ff4096_nH16_dH64_nl24_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,336390144,319612928,NVIDIA A100-SXM4-80GB,0,0,0,0,0,0,0,0,True
56,16384,medium,False,512,24,1024,4096,64,16,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 53, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 24, 'h_dim': 1024, 'mlp_dim': 4096, 'head_dim': 64, 'n_heads': 16, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpbkn117hl/throughput_results_bsz53.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz53__sl512_coslr0.0006to6e-06_h1024_ff4096_nH16_dH64_nl24_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,336390144,319612928,NVIDIA A100-SXM4-80GB,0,0,0,0,0,0,0,0,True
1,16384,small,False,512,12,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 1, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 12, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpcdtmiz66/throughput_results_bsz1.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz1__sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,110615040,98032128,NVIDIA A100-SXM4-80GB,1190.462890625,1321.39404296875,512,55.90593828473772,0.12315733883435917,17.887187491726603,0.03939325092137836,9158,False,109.61 G,49.93 GMACs,110.62 M
8,16384,small,False,512,12,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 8, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 12, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpcdtmiz66/throughput_results_bsz8.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz8__sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,110615040,98032128,NVIDIA A100-SXM4-80GB,1190.462890625,1320.79638671875,4096,60.911835534232004,0.12188769111754946,16.41717067347293,0.03279166232792354,67245,False,876.86 G,399.43 GMACs,110.62 M
16,16384,small,False,512,12,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 16, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 12, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpcdtmiz66/throughput_results_bsz16.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz16__sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,110615040,98032128,NVIDIA A100-SXM4-80GB,1190.462890625,1364.57763671875,8192,81.37374332972935,0.065333492696051,12.288976260413188,0.009867601318208383,100671,False,1753.73 G,798.86 GMACs,110.62 M
24,16384,small,False,512,12,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 24, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 12, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpcdtmiz66/throughput_results_bsz24.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz24__sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,110615040,98032128,NVIDIA A100-SXM4-80GB,1190.462890625,1308.73388671875,12288,105.55512292044503,0.0500182621245253,9.473723039986243,0.004487299503944637,116413,False,2630.61 G,1198.3 GMACs,110.62 M
32,16384,small,False,512,12,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 32, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 12, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpcdtmiz66/throughput_results_bsz32.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz32__sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,110615040,98032128,NVIDIA A100-SXM4-80GB,1190.462890625,1307.39013671875,16384,134.69879695347376,0.06738127105618794,7.423971279753965,0.0037159781708631006,121634,False,3507.36 G,1597.73 GMACs,110.62 M
40,16384,small,False,512,12,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 40, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 12, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpcdtmiz66/throughput_results_bsz40.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz40__sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,110615040,98032128,NVIDIA A100-SXM4-80GB,1190.462890625,1329.42138671875,20480,163.5841522216797,0.1605051103795237,6.1130616041880295,0.0059883573999475,125196,False,4384.44 G,1997.16 GMACs,110.62 M
48,16384,small,False,512,12,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 48, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 12, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpcdtmiz66/throughput_results_bsz48.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz48__sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,110615040,98032128,NVIDIA A100-SXM4-80GB,1190.462890625,1309.20263671875,24576,191.40112958635603,0.16685073678148454,5.2246295628512565,0.004549465414155219,128400,False,5261.27 G,2396.59 GMACs,110.62 M
56,16384,small,False,512,12,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 56, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 12, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpcdtmiz66/throughput_results_bsz56.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz56__sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,110615040,98032128,NVIDIA A100-SXM4-80GB,1190.462890625,1308.23388671875,28672,220.49358585902624,0.1464743848762741,4.535279319369206,0.0030094691782588156,130036,False,6138.11 G,2796.02 GMACs,110.62 M
64,16384,small,False,512,12,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 64, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 12, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpcdtmiz66/throughput_results_bsz64.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz64__sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,110615040,98032128,NVIDIA A100-SXM4-80GB,1190.462890625,1322.01513671875,32768,249.77059500558036,0.3154215692707804,4.0036738511098875,0.005052812924489375,131192,False
72,16384,small,False,512,12,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 72, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 12, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpcdtmiz66/throughput_results_bsz72.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz72__sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,110615040,98032128,NVIDIA A100-SXM4-80GB,1190.462890625,1309.671875,36864,280.8877737862723,0.6140047827008434,3.5601407157041325,0.007777299991620687,131241,False
80,16384,small,False,512,12,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 80, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 12, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpcdtmiz66/throughput_results_bsz80.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz80__sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,110615040,98032128,NVIDIA A100-SXM4-80GB,1190.462890625,1311.703125,40960,312.34916033063615,0.6308616538840274,3.201545344131719,0.006462295818479368,131135,False
88,16384,small,False,512,12,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 88, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 12, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpcdtmiz66/throughput_results_bsz88.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz88__sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,110615040,98032128,NVIDIA A100-SXM4-80GB,1190.462890625,1316.109375,45056,338.94950430733815,0.34081589262363743,2.950291967659179,0.0029661226907322074,132928,False
96,16384,small,False,512,12,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 96, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 12, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpcdtmiz66/throughput_results_bsz96.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz96__sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,110615040,98032128,NVIDIA A100-SXM4-80GB,1190.462890625,1308.890625,49152,367.89991542271207,0.4442841813673862,2.718130551487117,0.003278502551715896,133602,False
104,16384,small,False,512,12,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 104, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 12, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpcdtmiz66/throughput_results_bsz104.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz104__sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,110615040,98032128,NVIDIA A100-SXM4-80GB,1190.462890625,1311.046875,53248,397.8602207728795,0.6840665323282397,2.51344554642183,0.00432310628036007,133836,False
112,16384,small,False,512,12,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 112, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 12, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpcdtmiz66/throughput_results_bsz112.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz112__sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,110615040,98032128,NVIDIA A100-SXM4-80GB,1190.462890625,1313.578125,57344,426.4544895717076,0.5243690772103807,2.344916103484594,0.0028813108674946033,134467,False
120,16384,small,False,512,12,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 120, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 12, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpcdtmiz66/throughput_results_bsz120.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz120__sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,110615040,98032128,NVIDIA A100-SXM4-80GB,1190.462890625,1310.609375,61440,456.90208871024,0.4225500687002325,2.1886527216866893,0.0020249028547821546,134471,False
128,16384,small,False,512,12,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 128, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 12, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpcdtmiz66/throughput_results_bsz128.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz128__sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,110615040,98032128,NVIDIA A100-SXM4-80GB,1190.462890625,1309.140625,65536,485.0690394810268,0.4375902787109045,2.061562207866112,0.001859544720294116,135107,False
130,16384,small,False,512,12,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 130, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 12, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpcdtmiz66/throughput_results_bsz130.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz130__sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,110615040,98032128,NVIDIA A100-SXM4-80GB,1190.462890625,1309.52392578125,66560,493.6611066545759,0.6745484987318879,2.0256811535686143,0.0027728288712931767,134829,False
131,16384,small,False,512,12,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 130, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 12, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpcdtmiz66/throughput_results_bsz130.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz130__sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,110615040,98032128,NVIDIA A100-SXM4-80GB,0,0,0,0,0,0,0,0,True
132,16384,small,False,512,12,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 130, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 12, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpcdtmiz66/throughput_results_bsz130.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz130__sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,110615040,98032128,NVIDIA A100-SXM4-80GB,0,0,0,0,0,0,0,0,True
136,16384,small,False,512,12,768,3072,64,12,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 130, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 12, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpcdtmiz66/throughput_results_bsz130.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz130__sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,110615040,98032128,NVIDIA A100-SXM4-80GB,0,0,0,0,0,0,0,0,True
1,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 1, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmprdb2722t/throughput_results_bsz1.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz1__sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,27549696,19161088,NVIDIA A100-SXM4-80GB,361.09375,347.53662109375,512,19.427547454833984,0.26414431516782,51.473301111467826,0.6810494746352909,26354,False,20.42 G,9.66 GMACs,27.55 M
8,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 8, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmprdb2722t/throughput_results_bsz8.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz8__sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,27549696,19161088,NVIDIA A100-SXM4-80GB,361.09375,347.56396484375,4096,19.558619362967356,0.048178205930389885,51.12835325654009,0.12618802135547466,209422,False,163.37 G,77.31 GMACs,27.55 M
16,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 16, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmprdb2722t/throughput_results_bsz16.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz16__sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,27549696,19161088,NVIDIA A100-SXM4-80GB,361.09375,347.59521484375,8192,24.27487087249756,0.11701140577947258,41.19486382656557,0.19822074521763602,337468,False,326.74 G,154.62 GMACs,27.55 M
24,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 24, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmprdb2722t/throughput_results_bsz24.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz24__sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,27549696,19161088,NVIDIA A100-SXM4-80GB,361.09375,347.62646484375,12288,29.879435675484793,0.06266067391499344,33.4678342275544,0.07029638875517032,411253,False,490.11 G,231.93 GMACs,27.55 M
32,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 32, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmprdb2722t/throughput_results_bsz32.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz32__sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,27549696,19161088,NVIDIA A100-SXM4-80GB,361.09375,347.65771484375,16384,35.259359632219585,0.10228183781580863,28.361263801462005,0.082223653105009,464671,False,653.48 G,309.24 GMACs,27.55 M
40,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 40, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmprdb2722t/throughput_results_bsz40.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz40__sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,27549696,19161088,NVIDIA A100-SXM4-80GB,361.09375,347.68896484375,20480,41.228916713169646,0.11721439637304325,24.254821123655006,0.06890801230918217,496739,False,816.85 G,386.55 GMACs,27.55 M
48,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 48, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmprdb2722t/throughput_results_bsz48.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz48__sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,27549696,19161088,NVIDIA A100-SXM4-80GB,361.09375,347.72021484375,24576,48.350878034319194,0.12249865315834266,20.682147680755772,0.05237921125461408,508284,False,980.22 G,463.86 GMACs,27.55 M
56,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 56, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmprdb2722t/throughput_results_bsz56.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz56__sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,27549696,19161088,NVIDIA A100-SXM4-80GB,361.09375,347.75146484375,28672,55.44862856183733,0.08737477864633482,18.03471115403299,0.028337116888176906,517091,False,1143.59 G,541.17 GMACs,27.55 M
64,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 64, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmprdb2722t/throughput_results_bsz64.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz64__sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,27549696,19161088,NVIDIA A100-SXM4-80GB,361.09375,347.78271484375,32768,62.17426300048828,0.05257064709078234,16.083825553222024,0.013603227050979902,527035,False,1306.96 G,618.48 GMACs,27.55 M
72,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 72, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmprdb2722t/throughput_results_bsz72.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz72__sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,27549696,19161088,NVIDIA A100-SXM4-80GB,361.09375,347.814453125,36864,69.4577751159668,1.2444359402321592,14.397236282480955,0.2435557395699183,530740,False,1470.33 G,695.78 GMACs,27.55 M
80,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 80, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmprdb2722t/throughput_results_bsz80.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz80__sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,27549696,19161088,NVIDIA A100-SXM4-80GB,361.09375,347.845703125,40960,75.99099349975586,0.12546742414470752,13.159454218784662,0.021672293648667244,539011,False,1633.72 G,773.09 GMACs,27.55 M
88,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 88, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmprdb2722t/throughput_results_bsz88.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz88__sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,27549696,19161088,NVIDIA A100-SXM4-80GB,361.09375,347.876953125,45056,83.34178488595145,0.03959450255339614,11.99878309983934,0.005701479627770182,540617,False,1797.06 G,850.4 GMACs,27.55 M
96,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 96, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmprdb2722t/throughput_results_bsz96.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz96__sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,27549696,19161088,NVIDIA A100-SXM4-80GB,361.09375,347.908203125,49152,90.58662578037807,0.2407416372092627,11.039157175634745,0.029289087820617957,542597,False,1960.4 G,927.71 GMACs,27.55 M
104,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 104, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmprdb2722t/throughput_results_bsz104.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz104__sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,27549696,19161088,NVIDIA A100-SXM4-80GB,361.09375,347.939453125,53248,97.29230499267578,0.07979503515152689,10.27830515553394,0.008421671893173254,547299,False,2123.82 G,1005.02 GMACs,27.55 M
112,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 112, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmprdb2722t/throughput_results_bsz112.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz112__sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,27549696,19161088,NVIDIA A100-SXM4-80GB,361.09375,347.970703125,57344,105.07930047171456,0.12222927677836769,9.516622165458571,0.011072234797255099,545721,False,2287.16 G,1082.33 GMACs,27.55 M
120,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 120, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmprdb2722t/throughput_results_bsz120.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz120__sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,27549696,19161088,NVIDIA A100-SXM4-80GB,361.09375,348.001953125,61440,111.84174183436802,1.1706664687822586,8.941205524865211,0.09055689518823792,549348,False,2450.58 G,1159.64 GMACs,27.55 M
128,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 128, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmprdb2722t/throughput_results_bsz128.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz128__sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,27549696,19161088,NVIDIA A100-SXM4-80GB,361.09375,348.033203125,65536,119.20187595912388,1.3190139419139393,8.389129717580243,0.0896051843436521,549790,False,2613.92 G,1236.95 GMACs,27.55 M
136,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 136, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmprdb2722t/throughput_results_bsz136.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz136__sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,27549696,19161088,NVIDIA A100-SXM4-80GB,361.09375,348.06494140625,69632,126.7965327671596,0.23170055566833284,7.886650984663208,0.014426742963143547,549163,False,2777.27 G,1314.26 GMACs,27.55 M
144,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 144, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmprdb2722t/throughput_results_bsz144.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz144__sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,27549696,19161088,NVIDIA A100-SXM4-80GB,361.09375,348.09619140625,73728,133.41671207972936,0.3081224834756161,7.495312876563796,0.01728215153385999,552614,False,2940.69 G,1391.57 GMACs,27.55 M
152,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 152, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmprdb2722t/throughput_results_bsz152.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz152__sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,27549696,19161088,NVIDIA A100-SXM4-80GB,361.09375,348.12744140625,77824,140.28227342878068,0.1958848348033087,7.128484416156014,0.0099563215274295,554767,False,3104.03 G,1468.88 GMACs,27.55 M
160,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 160, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmprdb2722t/throughput_results_bsz160.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz160__sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,27549696,19161088,NVIDIA A100-SXM4-80GB,361.09375,348.15869140625,81920,147.24253300258093,0.40923577658941485,6.791515872539843,0.01886241284850106,556361,False,3267.37 G,1546.19 GMACs,27.55 M
168,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 168, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmprdb2722t/throughput_results_bsz168.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz168__sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,27549696,19161088,NVIDIA A100-SXM4-80GB,361.09375,348.18994140625,86016,154.32796042306083,0.3598422574770486,6.479707223880168,0.015112043328746237,557358,False,3430.79 G,1623.5 GMACs,27.55 M
176,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 176, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmprdb2722t/throughput_results_bsz176.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz176__sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,27549696,19161088,NVIDIA A100-SXM4-80GB,361.09375,348.22119140625,90112,162.17154039655412,0.5733743924585064,6.1663100538770514,0.021777395773358302,555659,False,3594.13 G,1700.81 GMACs,27.55 M
184,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 184, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmprdb2722t/throughput_results_bsz184.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz184__sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,27549696,19161088,NVIDIA A100-SXM4-80GB,361.09375,348.25244140625,94208,169.35131072998047,0.3877645814403193,5.904884914616541,0.013517516763559634,556287,False,3757.55 G,1778.12 GMACs,27.55 M
192,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 192, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmprdb2722t/throughput_results_bsz192.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz192__sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,27549696,19161088,NVIDIA A100-SXM4-80GB,361.09375,348.28369140625,98304,176.42777361188615,0.2402527802033291,5.668041825431893,0.007711019136722278,557191,False,3920.89 G,1855.43 GMACs,27.55 M
200,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 200, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmprdb2722t/throughput_results_bsz200.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz200__sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,27549696,19161088,NVIDIA A100-SXM4-80GB,361.09375,348.3154296875,102400,183.82063184465682,0.24861043623615467,5.440085750793633,0.007353113291985284,557065,False,4084.23 G,1932.74 GMACs,27.55 M
208,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 208, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmprdb2722t/throughput_results_bsz208.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz208__sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,27549696,19161088,NVIDIA A100-SXM4-80GB,361.09375,348.3466796875,106496,190.71854945591517,0.414227679233849,5.243328469374455,0.011427359365258294,558394,False,4247.65 G,2010.04 GMACs,27.55 M
216,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 216, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmprdb2722t/throughput_results_bsz216.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz216__sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,27549696,19161088,NVIDIA A100-SXM4-80GB,361.09375,348.3779296875,110592,197.88407679966517,0.33137616971744327,5.053463705482401,0.008451050374594156,558873,False,4410.99 G,2087.35 GMACs,27.55 M
224,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 224, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmprdb2722t/throughput_results_bsz224.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz224__sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,27549696,19161088,NVIDIA A100-SXM4-80GB,361.09375,348.4091796875,114688,206.3143583025251,1.1292452965427997,4.846972397983417,0.02613558317113745,555890,False,4574.33 G,2164.66 GMACs,27.55 M
232,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 232, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmprdb2722t/throughput_results_bsz232.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz232__sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,27549696,19161088,NVIDIA A100-SXM4-80GB,361.09375,348.4404296875,118784,213.216060093471,0.5637627999174558,4.6900782218826,0.012397728872030913,557106,False,4737.75 G,2241.97 GMACs,27.55 M
240,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 240, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmprdb2722t/throughput_results_bsz240.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz240__sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,27549696,19161088,NVIDIA A100-SXM4-80GB,361.09375,348.4716796875,122880,220.40132795061385,0.36220041342306425,4.537177744337701,0.0074695308921782525,557528,False
248,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 248, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmprdb2722t/throughput_results_bsz248.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz248__sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,27549696,19161088,NVIDIA A100-SXM4-80GB,361.09375,348.5029296875,126976,227.69086565290178,0.4682155410740475,4.391919707154294,0.009052898184109757,557668,False
256,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 256, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmprdb2722t/throughput_results_bsz256.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz256__sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,27549696,19161088,NVIDIA A100-SXM4-80GB,361.09375,348.5341796875,131072,234.38916996547155,0.6034920063725299,4.266408725912176,0.01097849287832673,559207,False
264,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 264, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmprdb2722t/throughput_results_bsz264.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz264__sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,27549696,19161088,NVIDIA A100-SXM4-80GB,361.09375,348.56591796875,135168,241.44389016287667,0.47186826443317614,4.141749038774209,0.00809500613280422,559832,False
272,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 272, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmprdb2722t/throughput_results_bsz272.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz272__sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,27549696,19161088,NVIDIA A100-SXM4-80GB,361.09375,348.59716796875,139264,249.33627864292689,1.5778457025336565,4.010647810429924,0.02496113470941074,558539,False
280,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 280, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmprdb2722t/throughput_results_bsz280.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz280__sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,27549696,19161088,NVIDIA A100-SXM4-80GB,361.09375,348.62841796875,143360,256.78623744419644,0.4600615032375837,3.8942897016329203,0.006967385779140012,558285,False
288,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 288, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmprdb2722t/throughput_results_bsz288.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz288__sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,27549696,19161088,NVIDIA A100-SXM4-80GB,361.09375,348.65966796875,147456,263.02003696986606,0.2542725924581306,3.801991709531122,0.003676964446903846,560626,False
296,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 296, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmprdb2722t/throughput_results_bsz296.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz296__sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,27549696,19161088,NVIDIA A100-SXM4-80GB,361.09375,348.69091796875,151552,270.04820469447543,0.6446210674475644,3.7030425776441303,0.008782746140901567,561204,False
304,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 304, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmprdb2722t/throughput_results_bsz304.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz304__sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,27549696,19161088,NVIDIA A100-SXM4-80GB,361.09375,348.72216796875,155648,277.407461983817,0.37045009935242085,3.604805699344658,0.004806834409937906,561081,False
312,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 312, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmprdb2722t/throughput_results_bsz312.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz312__sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,27549696,19161088,NVIDIA A100-SXM4-80GB,361.09375,348.75341796875,159744,284.50064740862166,1.1722133643085964,3.5149304899954172,0.014327967627797358,561489,False
320,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 320, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmprdb2722t/throughput_results_bsz320.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz320__sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,27549696,19161088,NVIDIA A100-SXM4-80GB,361.09375,349.5322265625,163840,291.2224600655692,0.36998853156913386,3.4338010872336167,0.004360936002361484,562594,False
328,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 328, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmprdb2722t/throughput_results_bsz328.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz328__sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,27549696,19161088,NVIDIA A100-SXM4-80GB,361.09375,348.81640625,167936,298.9032222202846,0.48806903657781237,3.345564469234874,0.005461298157450453,561841,False
336,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 336, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmprdb2722t/throughput_results_bsz336.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz336__sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,27549696,19161088,NVIDIA A100-SXM4-80GB,361.09375,348.84765625,172032,306.08480181012834,0.614843234374551,3.267068453207042,0.00654947493660904,562040,False
340,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 340, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmprdb2722t/throughput_results_bsz340.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz340__sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,27549696,19161088,NVIDIA A100-SXM4-80GB,361.09375,348.86328125,174080,309.6932460239955,0.907267319717466,3.229001642233161,0.009411571838067288,562105,False
341,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 340, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmprdb2722t/throughput_results_bsz340.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz340__sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,27549696,19161088,NVIDIA A100-SXM4-80GB,0,0,0,0,0,0,0,0,True
342,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 340, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmprdb2722t/throughput_results_bsz340.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz340__sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,27549696,19161088,NVIDIA A100-SXM4-80GB,0,0,0,0,0,0,0,0,True
344,16384,mini,False,512,4,512,2048,32,8,default,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': '/data/languini_data/books', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 340, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'test_every': -1, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/ibex/user/serikoo/languini_proj/Languini/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmprdb2722t/throughput_results_bsz340.pkl', 'n_gpus': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz340__sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_gpus1_defaultCompile_fp16'})",forward and backward,27549696,19161088,NVIDIA A100-SXM4-80GB,0,0,0,0,0,0,0,0,True
1,16384,mini,512,4,512,2048,32,8,default,False,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': 'data/books', 'relative_log_path': 'logs', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 1, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/home/imanol/languini-kitchen/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmphd5yrmdi/throughput_results_bsz1.pkl', 'n_workers': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz1_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_workers1_defaultCompile_fp16_seed0'})",forward and backward,27549696,19161088,NVIDIA GeForce RTX 4090,361.09375,347.53662109375,512,18.19034276689802,1.7635365799096947,54.97422521469775,4.766481924288346,28147,False,20.42 G,9.66 GMACs,27.55 M
8,16384,mini,512,4,512,2048,32,8,default,False,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': 'data/books', 'relative_log_path': 'logs', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 8, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/home/imanol/languini-kitchen/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmphd5yrmdi/throughput_results_bsz8.pkl', 'n_workers': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz8_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_workers1_defaultCompile_fp16_seed0'})",forward and backward,27549696,19161088,NVIDIA GeForce RTX 4090,361.09375,347.56396484375,4096,18.074244362967356,0.20400988765817737,55.32734757359583,0.6262925026303601,226621,False,163.37 G,77.31 GMACs,27.55 M
16,16384,mini,512,4,512,2048,32,8,default,False,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': 'data/books', 'relative_log_path': 'logs', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 16, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/home/imanol/languini-kitchen/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmphd5yrmdi/throughput_results_bsz16.pkl', 'n_workers': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz16_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_workers1_defaultCompile_fp16_seed0'})",forward and backward,27549696,19161088,NVIDIA GeForce RTX 4090,361.09375,347.59521484375,8192,24.723144939967565,0.32915940340206906,40.44792854744765,0.5349281449160386,331349,False,326.74 G,154.62 GMACs,27.55 M
24,16384,mini,512,4,512,2048,32,8,default,False,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': 'data/books', 'relative_log_path': 'logs', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 24, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/home/imanol/languini-kitchen/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmphd5yrmdi/throughput_results_bsz24.pkl', 'n_workers': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz24_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_workers1_defaultCompile_fp16_seed0'})",forward and backward,27549696,19161088,NVIDIA GeForce RTX 4090,361.09375,347.62646484375,12288,33.29668344770159,0.396473348968348,30.033021203768815,0.35139299028436066,369046,False,490.11 G,231.93 GMACs,27.55 M
32,16384,mini,512,4,512,2048,32,8,default,False,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': 'data/books', 'relative_log_path': 'logs', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 32, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/home/imanol/languini-kitchen/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmphd5yrmdi/throughput_results_bsz32.pkl', 'n_workers': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz32_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_workers1_defaultCompile_fp16_seed0'})",forward and backward,27549696,19161088,NVIDIA GeForce RTX 4090,361.09375,347.65771484375,16384,44.38938767569406,1.4163958389996179,22.527907059812,0.7128716988029264,369097,False,653.48 G,309.24 GMACs,27.55 M
40,16384,mini,512,4,512,2048,32,8,default,False,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': 'data/books', 'relative_log_path': 'logs', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 40, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/home/imanol/languini-kitchen/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmphd5yrmdi/throughput_results_bsz40.pkl', 'n_workers': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz40_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_workers1_defaultCompile_fp16_seed0'})",forward and backward,27549696,19161088,NVIDIA GeForce RTX 4090,361.09375,347.68896484375,20480,54.85103797912598,0.26436603426846716,18.231195558788848,0.08816962007557355,373375,False,816.85 G,386.55 GMACs,27.55 M
48,16384,mini,512,4,512,2048,32,8,default,False,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': 'data/books', 'relative_log_path': 'logs', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 48, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/home/imanol/languini-kitchen/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmphd5yrmdi/throughput_results_bsz48.pkl', 'n_workers': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz48_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_workers1_defaultCompile_fp16_seed0'})",forward and backward,27549696,19161088,NVIDIA GeForce RTX 4090,361.09375,347.72021484375,24576,65.24635423932757,0.5332853310973186,15.326526848257904,0.12448460631171923,376665,False,980.22 G,463.86 GMACs,27.55 M
56,16384,mini,512,4,512,2048,32,8,default,False,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': 'data/books', 'relative_log_path': 'logs', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 56, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/home/imanol/languini-kitchen/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmphd5yrmdi/throughput_results_bsz56.pkl', 'n_workers': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz56_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_workers1_defaultCompile_fp16_seed0'})",forward and backward,27549696,19161088,NVIDIA GeForce RTX 4090,361.09375,347.75146484375,28672,77.41303253173828,0.5140903459729339,12.91772156826454,0.0859428081821331,370377,False,1.14 T,541.17 GMACs,27.55 M
64,16384,mini,512,4,512,2048,32,8,default,False,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': 'data/books', 'relative_log_path': 'logs', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 64, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/home/imanol/languini-kitchen/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmphd5yrmdi/throughput_results_bsz64.pkl', 'n_workers': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz64_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_workers1_defaultCompile_fp16_seed0'})",forward and backward,27549696,19161088,NVIDIA GeForce RTX 4090,361.09375,347.78271484375,32768,86.41697093418666,0.4959285157152978,11.571801107927966,0.06543447986461833,379185,False,1.31 T,618.48 GMACs,27.55 M
72,16384,mini,512,4,512,2048,32,8,default,False,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': 'data/books', 'relative_log_path': 'logs', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 72, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/home/imanol/languini-kitchen/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmphd5yrmdi/throughput_results_bsz72.pkl', 'n_workers': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz72_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_workers1_defaultCompile_fp16_seed0'})",forward and backward,27549696,19161088,NVIDIA GeForce RTX 4090,361.09375,347.814453125,36864,97.25311715262276,0.23561395355824968,10.28244676652024,0.024877434737221187,379052,False
80,16384,mini,512,4,512,2048,32,8,default,False,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': 'data/books', 'relative_log_path': 'logs', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 80, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/home/imanol/languini-kitchen/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmphd5yrmdi/throughput_results_bsz80.pkl', 'n_workers': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz80_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_workers1_defaultCompile_fp16_seed0'})",forward and backward,27549696,19161088,NVIDIA GeForce RTX 4090,361.09375,347.845703125,40960,108.39629581996373,0.5751016883365186,9.225407496035732,0.04891233578002277,377873,False
88,16384,mini,512,4,512,2048,32,8,default,False,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': 'data/books', 'relative_log_path': 'logs', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 88, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/home/imanol/languini-kitchen/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmphd5yrmdi/throughput_results_bsz88.pkl', 'n_workers': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz88_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_workers1_defaultCompile_fp16_seed0'})",forward and backward,27549696,19161088,NVIDIA GeForce RTX 4090,361.09375,347.876953125,45056,118.48564692905971,0.3325728279281958,8.439840823916207,0.02367281809189049,380265,False
96,16384,mini,512,4,512,2048,32,8,default,False,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': 'data/books', 'relative_log_path': 'logs', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 96, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/home/imanol/languini-kitchen/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmphd5yrmdi/throughput_results_bsz96.pkl', 'n_workers': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz96_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_workers1_defaultCompile_fp16_seed0'})",forward and backward,27549696,19161088,NVIDIA GeForce RTX 4090,361.09375,347.908203125,49152,128.94910866873605,0.39547266459916236,7.754997380935382,0.023815660624555424,381174,False
98,16384,mini,512,4,512,2048,32,8,default,False,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': 'data/books', 'relative_log_path': 'logs', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 98, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/home/imanol/languini-kitchen/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmphd5yrmdi/throughput_results_bsz98.pkl', 'n_workers': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz98_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_workers1_defaultCompile_fp16_seed0'})",forward and backward,27549696,19161088,NVIDIA GeForce RTX 4090,361.09375,351.791015625,50176,132.81212071010046,0.38286109411432145,7.5294332674860245,0.0217150708524298,377797,False
99,16384,mini,512,4,512,2048,32,8,default,False,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': 'data/books', 'relative_log_path': 'logs', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 99, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/home/imanol/languini-kitchen/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmphd5yrmdi/throughput_results_bsz99.pkl', 'n_workers': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz99_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_workers1_defaultCompile_fp16_seed0'})",forward and backward,27549696,19161088,NVIDIA GeForce RTX 4090,361.09375,348.544921875,50688,134.00825718470983,0.5094753110654339,7.4622267389214185,0.028415828841238496,378245,False
100,16384,mini,512,4,512,2048,32,8,default,False,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': 'data/books', 'relative_log_path': 'logs', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 99, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/home/imanol/languini-kitchen/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmphd5yrmdi/throughput_results_bsz99.pkl', 'n_workers': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz99_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_workers1_defaultCompile_fp16_seed0'})",forward and backward,27549696,19161088,NVIDIA GeForce RTX 4090,0,0,0,0,0,0,0,0,True
104,16384,mini,512,4,512,2048,32,8,default,False,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': 'data/books', 'relative_log_path': 'logs', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 99, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 512, 'mlp_dim': 2048, 'head_dim': 32, 'n_heads': 8, 'project_path': '/home/imanol/languini-kitchen/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmphd5yrmdi/throughput_results_bsz99.pkl', 'n_workers': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz99_sl512_coslr0.0006to6e-06_h512_ff2048_nH8_dH32_nl4_clip0.0_decay500k_workers1_defaultCompile_fp16_seed0'})",forward and backward,27549696,19161088,NVIDIA GeForce RTX 4090,0,0,0,0,0,0,0,0,True
1,16384,small,512,12,768,3072,64,12,default,False,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': 'data/books', 'relative_log_path': 'logs', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 1, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 12, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/home/imanol/languini-kitchen/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmppuf_qezv/throughput_results_bsz1.pkl', 'n_workers': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz1_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_workers1_defaultCompile_fp16_seed0'})",forward and backward,110615040,98032128,NVIDIA GeForce RTX 4090,1190.462890625,1318.64404296875,512,52.62790625435965,0.4503342401942124,19.001325934701438,0.16190103799043112,9729,False,109.61 G,49.93 GMACs,110.62 M
8,16384,small,512,12,768,3072,64,12,default,False,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': 'data/books', 'relative_log_path': 'logs', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 8, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 12, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/home/imanol/languini-kitchen/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmppuf_qezv/throughput_results_bsz8.pkl', 'n_workers': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz8_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_workers1_defaultCompile_fp16_seed0'})",forward and backward,110615040,98032128,NVIDIA GeForce RTX 4090,1190.462890625,1324.42138671875,4096,62.053353445870535,0.3665522727058567,16.115164523256674,0.0948807815214262,66008,False,876.86 G,399.43 GMACs,110.62 M
16,16384,small,512,12,768,3072,64,12,default,False,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': 'data/books', 'relative_log_path': 'logs', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 16, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 12, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/home/imanol/languini-kitchen/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmppuf_qezv/throughput_results_bsz16.pkl', 'n_workers': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz16_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_workers1_defaultCompile_fp16_seed0'})",forward and backward,110615040,98032128,NVIDIA GeForce RTX 4090,1190.462890625,1361.70263671875,8192,96.6688701084682,5.046538562280081,10.344591789248605,0.46255254807221835,84743,False,1.75 T,798.86 GMACs,110.62 M
24,16384,small,512,12,768,3072,64,12,default,False,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': 'data/books', 'relative_log_path': 'logs', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 24, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 12, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/home/imanol/languini-kitchen/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmppuf_qezv/throughput_results_bsz24.pkl', 'n_workers': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz24_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_workers1_defaultCompile_fp16_seed0'})",forward and backward,110615040,98032128,NVIDIA GeForce RTX 4090,1190.462890625,1308.73388671875,12288,140.47836412702287,0.39636235950475324,7.118533919542111,0.020004281289023672,87473,False
32,16384,small,512,12,768,3072,64,12,default,False,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': 'data/books', 'relative_log_path': 'logs', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 32, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 12, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/home/imanol/languini-kitchen/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmppuf_qezv/throughput_results_bsz32.pkl', 'n_workers': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz32_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_workers1_defaultCompile_fp16_seed0'})",forward and backward,110615040,98032128,NVIDIA GeForce RTX 4090,1190.462890625,1307.39013671875,16384,184.71065630231584,0.3083263206400061,5.413872810691011,0.009020123494151747,88701,False
34,16384,small,512,12,768,3072,64,12,default,False,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': 'data/books', 'relative_log_path': 'logs', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 34, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 12, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/home/imanol/languini-kitchen/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmppuf_qezv/throughput_results_bsz34.pkl', 'n_workers': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz34_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_workers1_defaultCompile_fp16_seed0'})",forward and backward,110615040,98032128,NVIDIA GeForce RTX 4090,1190.462890625,1318.02294921875,17408,200.3027627127511,0.27726995076179456,4.992442373019455,0.006911565638229919,86908,False
35,16384,small,512,12,768,3072,64,12,default,False,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': 'data/books', 'relative_log_path': 'logs', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 35, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 12, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/home/imanol/languini-kitchen/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmppuf_qezv/throughput_results_bsz35.pkl', 'n_workers': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz35_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_workers1_defaultCompile_fp16_seed0'})",forward and backward,110615040,98032128,NVIDIA GeForce RTX 4090,1190.462890625,1333.65185546875,17920,204.91262272426061,0.3441257886079624,4.880128840796908,0.00818440233123677,87452,False
36,16384,small,512,12,768,3072,64,12,default,False,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': 'data/books', 'relative_log_path': 'logs', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 35, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 12, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/home/imanol/languini-kitchen/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmppuf_qezv/throughput_results_bsz35.pkl', 'n_workers': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz35_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_workers1_defaultCompile_fp16_seed0'})",forward and backward,110615040,98032128,NVIDIA GeForce RTX 4090,0,0,0,0,0,0,0,0,True
40,16384,small,512,12,768,3072,64,12,default,False,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': 'data/books', 'relative_log_path': 'logs', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 35, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 12, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/home/imanol/languini-kitchen/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmppuf_qezv/throughput_results_bsz35.pkl', 'n_workers': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz35_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl12_clip0.0_decay500k_workers1_defaultCompile_fp16_seed0'})",forward and backward,110615040,98032128,NVIDIA GeForce RTX 4090,0,0,0,0,0,0,0,0,True
1,16384,tiny,512,4,768,3072,64,12,default,False,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': 'data/books', 'relative_log_path': 'logs', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 1, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/home/imanol/languini-kitchen/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpl_8avyyr/throughput_results_bsz1.pkl', 'n_workers': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz1_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_workers1_defaultCompile_fp16_seed0'})",forward and backward,53912064,41329152,NVIDIA GeForce RTX 4090,462.158203125,663.72998046875,512,22.76849624088832,2.193748828823281,43.92033577536716,4.388533915305199,22487,False,45.13 G,20.94 GMACs,53.91 M
8,16384,tiny,512,4,768,3072,64,12,default,False,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': 'data/books', 'relative_log_path': 'logs', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 8, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/home/imanol/languini-kitchen/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpl_8avyyr/throughput_results_bsz8.pkl', 'n_workers': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz8_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_workers1_defaultCompile_fp16_seed0'})",forward and backward,53912064,41329152,NVIDIA GeForce RTX 4090,462.158203125,664.38232421875,4096,24.383593014308385,0.0753673878037299,41.01118319245224,0.12680322860549506,167982,False,361.02 G,167.5 GMACs,53.91 M
16,16384,tiny,512,4,768,3072,64,12,default,False,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': 'data/books', 'relative_log_path': 'logs', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 16, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/home/imanol/languini-kitchen/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpl_8avyyr/throughput_results_bsz16.pkl', 'n_workers': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz16_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_workers1_defaultCompile_fp16_seed0'})",forward and backward,53912064,41329152,NVIDIA GeForce RTX 4090,462.158203125,675.03857421875,8192,38.92619405473982,0.1545196484935561,25.689642264891187,0.10178771351715672,210450,False,722.04 G,335.01 GMACs,53.91 M
24,16384,tiny,512,4,768,3072,64,12,default,False,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': 'data/books', 'relative_log_path': 'logs', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 24, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/home/imanol/languini-kitchen/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpl_8avyyr/throughput_results_bsz24.pkl', 'n_workers': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz24_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_workers1_defaultCompile_fp16_seed0'})",forward and backward,53912064,41329152,NVIDIA GeForce RTX 4090,462.158203125,660.56982421875,12288,56.62994793483189,0.1515819282174572,17.65850113707982,0.04706006703254275,216988,False,1.08 T,502.51 GMACs,53.91 M
32,16384,tiny,512,4,768,3072,64,12,default,False,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': 'data/books', 'relative_log_path': 'logs', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 32, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/home/imanol/languini-kitchen/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpl_8avyyr/throughput_results_bsz32.pkl', 'n_workers': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz32_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_workers1_defaultCompile_fp16_seed0'})",forward and backward,53912064,41329152,NVIDIA GeForce RTX 4090,462.158203125,658.10107421875,16384,74.45357949393136,0.5988770060108114,13.431187684958909,0.10565223289243975,220057,False,1.44 T,670.01 GMACs,53.91 M
40,16384,tiny,512,4,768,3072,64,12,default,False,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': 'data/books', 'relative_log_path': 'logs', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 40, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/home/imanol/languini-kitchen/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpl_8avyyr/throughput_results_bsz40.pkl', 'n_workers': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz40_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_workers1_defaultCompile_fp16_seed0'})",forward and backward,53912064,41329152,NVIDIA GeForce RTX 4090,462.158203125,666.00732421875,20480,91.86860057285854,0.2009191642254068,10.885111929041813,0.023794922115307388,222927,False,1.81 T,837.52 GMACs,53.91 M
48,16384,tiny,512,4,768,3072,64,12,default,False,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': 'data/books', 'relative_log_path': 'logs', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 48, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/home/imanol/languini-kitchen/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpl_8avyyr/throughput_results_bsz48.pkl', 'n_workers': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz48_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_workers1_defaultCompile_fp16_seed0'})",forward and backward,53912064,41329152,NVIDIA GeForce RTX 4090,462.158203125,659.91357421875,24576,109.52920641217914,0.249142334638374,9.129984894045618,0.020783032853546015,224379,False
56,16384,tiny,512,4,768,3072,64,12,default,False,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': 'data/books', 'relative_log_path': 'logs', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 56, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/home/imanol/languini-kitchen/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpl_8avyyr/throughput_results_bsz56.pkl', 'n_workers': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz56_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_workers1_defaultCompile_fp16_seed0'})",forward and backward,53912064,41329152,NVIDIA GeForce RTX 4090,462.158203125,660.06982421875,28672,127.4810562133789,0.21499665753517652,7.844302751353042,0.013217599655501039,224912,False
64,16384,tiny,512,4,768,3072,64,12,default,False,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': 'data/books', 'relative_log_path': 'logs', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 64, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/home/imanol/languini-kitchen/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpl_8avyyr/throughput_results_bsz64.pkl', 'n_workers': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz64_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_workers1_defaultCompile_fp16_seed0'})",forward and backward,53912064,41329152,NVIDIA GeForce RTX 4090,462.158203125,661.60107421875,32768,143.78897530691964,0.22939251967656982,6.954636110769171,0.011080734917610713,227890,False
72,16384,tiny,512,4,768,3072,64,12,default,False,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': 'data/books', 'relative_log_path': 'logs', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 72, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/home/imanol/languini-kitchen/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpl_8avyyr/throughput_results_bsz72.pkl', 'n_workers': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz72_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_workers1_defaultCompile_fp16_seed0'})",forward and backward,53912064,41329152,NVIDIA GeForce RTX 4090,462.158203125,659.3828125,36864,162.35889434814453,0.19076355843630624,6.159194443981062,0.007237736397436563,227053,False
76,16384,tiny,512,4,768,3072,64,12,default,False,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': 'data/books', 'relative_log_path': 'logs', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 76, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/home/imanol/languini-kitchen/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpl_8avyyr/throughput_results_bsz76.pkl', 'n_workers': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz76_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_workers1_defaultCompile_fp16_seed0'})",forward and backward,53912064,41329152,NVIDIA GeForce RTX 4090,462.158203125,661.1484375,38912,171.92203630719865,0.17245378377152693,5.816590016495334,0.005835461769454431,226335,False
78,16384,tiny,512,4,768,3072,64,12,default,False,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': 'data/books', 'relative_log_path': 'logs', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 78, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/home/imanol/languini-kitchen/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpl_8avyyr/throughput_results_bsz78.pkl', 'n_workers': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz78_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_workers1_defaultCompile_fp16_seed0'})",forward and backward,53912064,41329152,NVIDIA GeForce RTX 4090,462.158203125,664.28125,39936,175.4353790283203,0.12289029885979687,5.7001045372870385,0.003989532512910507,227639,False
79,16384,tiny,512,4,768,3072,64,12,default,False,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': 'data/books', 'relative_log_path': 'logs', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 79, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/home/imanol/languini-kitchen/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpl_8avyyr/throughput_results_bsz79.pkl', 'n_workers': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz79_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_workers1_defaultCompile_fp16_seed0'})",forward and backward,53912064,41329152,NVIDIA GeForce RTX 4090,462.158203125,662.16015625,40448,177.56490107945032,0.1389691324809118,5.631743626813703,0.004404715600853864,227793,False
80,16384,tiny,512,4,768,3072,64,12,default,False,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': 'data/books', 'relative_log_path': 'logs', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 79, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 4, 'h_dim': 768, 'mlp_dim': 3072, 'head_dim': 64, 'n_heads': 12, 'project_path': '/home/imanol/languini-kitchen/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpl_8avyyr/throughput_results_bsz79.pkl', 'n_workers': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz79_sl512_coslr0.0006to6e-06_h768_ff3072_nH12_dH64_nl4_clip0.0_decay500k_workers1_defaultCompile_fp16_seed0'})",forward and backward,53912064,41329152,NVIDIA GeForce RTX 4090,0,0,0,0,0,0,0,0,True
1,16384,medium,512,24,1024,4096,64,16,default,False,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': 'data/books', 'relative_log_path': 'logs', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 1, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 24, 'h_dim': 1024, 'mlp_dim': 4096, 'head_dim': 64, 'n_heads': 16, 'project_path': '/home/imanol/languini-kitchen/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpxeilmos3/throughput_results_bsz1.pkl', 'n_workers': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz1_sl512_coslr0.0006to6e-06_h1024_ff4096_nH16_dH64_nl24_clip0.0_decay500k_workers1_defaultCompile_fp16_seed0'})",forward and backward,336390144,319612928,NVIDIA GeForce RTX 4090,2819.2265625,3897.93505859375,512,113.70119530814034,1.2126814454416766,8.794982298030474,0.09195307766391543,4503,False,352.42 G,163.21 GMACs,336.39 M
8,16384,medium,512,24,1024,4096,64,16,default,False,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': 'data/books', 'relative_log_path': 'logs', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 8, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 24, 'h_dim': 1024, 'mlp_dim': 4096, 'head_dim': 64, 'n_heads': 16, 'project_path': '/home/imanol/languini-kitchen/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpxeilmos3/throughput_results_bsz8.pkl', 'n_workers': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz8_sl512_coslr0.0006to6e-06_h1024_ff4096_nH16_dH64_nl24_clip0.0_decay500k_workers1_defaultCompile_fp16_seed0'})",forward and backward,336390144,319612928,NVIDIA GeForce RTX 4090,2819.2265625,3897.96240234375,4096,154.34756578717912,2.79947629192537,6.47888416574604,0.11590090472474124,26538,False
10,16384,medium,512,24,1024,4096,64,16,default,False,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': 'data/books', 'relative_log_path': 'logs', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 10, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 24, 'h_dim': 1024, 'mlp_dim': 4096, 'head_dim': 64, 'n_heads': 16, 'project_path': '/home/imanol/languini-kitchen/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpxeilmos3/throughput_results_bsz10.pkl', 'n_workers': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz10_sl512_coslr0.0006to6e-06_h1024_ff4096_nH16_dH64_nl24_clip0.0_decay500k_workers1_defaultCompile_fp16_seed0'})",forward and backward,336390144,319612928,NVIDIA GeForce RTX 4090,2819.2265625,3897.97021484375,5120,178.04710170200892,0.9671261922335646,5.616491312920467,0.030387441193406247,28756,False
11,16384,medium,512,24,1024,4096,64,16,default,False,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': 'data/books', 'relative_log_path': 'logs', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 11, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 24, 'h_dim': 1024, 'mlp_dim': 4096, 'head_dim': 64, 'n_heads': 16, 'project_path': '/home/imanol/languini-kitchen/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpxeilmos3/throughput_results_bsz11.pkl', 'n_workers': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz11_sl512_coslr0.0006to6e-06_h1024_ff4096_nH16_dH64_nl24_clip0.0_decay500k_workers1_defaultCompile_fp16_seed0'})",forward and backward,336390144,319612928,NVIDIA GeForce RTX 4090,2819.2265625,3902.84912109375,5632,192.95385088239397,1.1807568932744432,5.182586382323634,0.03152327482098855,29188,False
12,16384,medium,512,24,1024,4096,64,16,default,False,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': 'data/books', 'relative_log_path': 'logs', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 11, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 24, 'h_dim': 1024, 'mlp_dim': 4096, 'head_dim': 64, 'n_heads': 16, 'project_path': '/home/imanol/languini-kitchen/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpxeilmos3/throughput_results_bsz11.pkl', 'n_workers': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz11_sl512_coslr0.0006to6e-06_h1024_ff4096_nH16_dH64_nl24_clip0.0_decay500k_workers1_defaultCompile_fp16_seed0'})",forward and backward,336390144,319612928,NVIDIA GeForce RTX 4090,0,0,0,0,0,0,0,0,True
16,16384,medium,512,24,1024,4096,64,16,default,False,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': 'data/books', 'relative_log_path': 'logs', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 11, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 24, 'h_dim': 1024, 'mlp_dim': 4096, 'head_dim': 64, 'n_heads': 16, 'project_path': '/home/imanol/languini-kitchen/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpxeilmos3/throughput_results_bsz11.pkl', 'n_workers': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz11_sl512_coslr0.0006to6e-06_h1024_ff4096_nH16_dH64_nl24_clip0.0_decay500k_workers1_defaultCompile_fp16_seed0'})",forward and backward,336390144,319612928,NVIDIA GeForce RTX 4090,0,0,0,0,0,0,0,0,True
1,16384,large,512,24,1536,6144,96,16,default,False,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': 'data/books', 'relative_log_path': 'logs', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 1, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 24, 'h_dim': 1536, 'mlp_dim': 6144, 'head_dim': 96, 'n_heads': 16, 'project_path': '/home/imanol/languini-kitchen/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpjoisf1k0/throughput_results_bsz1.pkl', 'n_workers': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz1_sl512_coslr0.0006to6e-06_h1536_ff6144_nH16_dH96_nl24_clip0.0_decay500k_workers1_defaultCompile_fp16_seed0'})",forward and backward,731077632,705911808,NVIDIA GeForce RTX 4090,4324.83984375,8431.27490234375,512,156.9135295322963,6.167777161355053,6.372936756828083,0.23270027135214646,3263,False,760.5 G,360.78 GMACs,731.08 M
5,16384,large,512,24,1536,6144,96,16,default,False,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': 'data/books', 'relative_log_path': 'logs', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 5, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 24, 'h_dim': 1536, 'mlp_dim': 6144, 'head_dim': 96, 'n_heads': 16, 'project_path': '/home/imanol/languini-kitchen/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpjoisf1k0/throughput_results_bsz5.pkl', 'n_workers': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz5_sl512_coslr0.0006to6e-06_h1536_ff6144_nH16_dH96_nl24_clip0.0_decay500k_workers1_defaultCompile_fp16_seed0'})",forward and backward,731077632,705911808,NVIDIA GeForce RTX 4090,4324.83984375,8440.29052734375,2560,206.80347660609655,2.4746875258089998,4.835508650102259,0.05659218163370316,12379,False
6,16384,large,512,24,1536,6144,96,16,default,False,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': 'data/books', 'relative_log_path': 'logs', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 5, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 24, 'h_dim': 1536, 'mlp_dim': 6144, 'head_dim': 96, 'n_heads': 16, 'project_path': '/home/imanol/languini-kitchen/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpjoisf1k0/throughput_results_bsz5.pkl', 'n_workers': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz5_sl512_coslr0.0006to6e-06_h1536_ff6144_nH16_dH96_nl24_clip0.0_decay500k_workers1_defaultCompile_fp16_seed0'})",forward and backward,731077632,705911808,NVIDIA GeForce RTX 4090,0,0,0,0,0,0,0,0,True
7,16384,large,512,24,1536,6144,96,16,default,False,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': 'data/books', 'relative_log_path': 'logs', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 5, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 24, 'h_dim': 1536, 'mlp_dim': 6144, 'head_dim': 96, 'n_heads': 16, 'project_path': '/home/imanol/languini-kitchen/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpjoisf1k0/throughput_results_bsz5.pkl', 'n_workers': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz5_sl512_coslr0.0006to6e-06_h1536_ff6144_nH16_dH96_nl24_clip0.0_decay500k_workers1_defaultCompile_fp16_seed0'})",forward and backward,731077632,705911808,NVIDIA GeForce RTX 4090,0,0,0,0,0,0,0,0,True
8,16384,large,512,24,1536,6144,96,16,default,False,<class 'torch._dynamo.eval_frame.OptimizedModule'>,"Munch({'data_root': 'data/books', 'relative_log_path': 'logs', 'dataset': 'books_16384', 'vocab_size': 16384, 'debug': False, 'seed': 0, 'gradient_accumulation_steps': 1, 'train_batch_size': 5, 'eval_batch_size': 16, 'test_batch_size': 16, 'seq_len': 512, 'max_eval_steps': 500, 'max_train_steps': 500000, 'decay_steps': 500000, 'max_lr': 0.0006, 'min_lr': 6e-06, 'grad_clip_norm': 0.0, 'tokens_per_second': 0, 'eval_every': 1000, 'log_terminal_every': 100, 'log_metrics_every': 100, 'log_grads_every': 1000, 'log_activations_every': -1, 'log_ckpt_every': 5000, 'logger_type': 'all', 'wandb_project_name': 'gpt', 'use_flash': False, 'n_layers': 24, 'h_dim': 1536, 'mlp_dim': 6144, 'head_dim': 96, 'n_heads': 16, 'project_path': '/home/imanol/languini-kitchen/languini/projects/gpt', 'compile': 'default', 'results_pickle_file': '/tmp/tmpjoisf1k0/throughput_results_bsz5.pkl', 'n_workers': 1, 'device': 'cuda', 'exp_name': 'GPT_books16384_bsz5_sl512_coslr0.0006to6e-06_h1536_ff6144_nH16_dH96_nl24_clip0.0_decay500k_workers1_defaultCompile_fp16_seed0'})",forward and backward,731077632,705911808,NVIDIA GeForce RTX 4090,0,0,0,0,0,0,0,0,True
